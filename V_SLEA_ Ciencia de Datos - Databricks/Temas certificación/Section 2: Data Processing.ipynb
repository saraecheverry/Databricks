{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b26105d-ecbc-4b29-a095-150341bd6dbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18dd7b18-1217-4b74-8b5e-4fb553bc1adb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Compute summary statistics on a Spark DataFrame using .summary() or dbutils data summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97b8cfdc-848c-43a8-aecb-a169a8117ac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "# Crear SparkSession\n",
    "spark = SparkSession.builder.appName(\"ResumenVinos\").getOrCreate()\n",
    "\n",
    "# Definir esquema\n",
    "schema = StructType([\n",
    "    StructField(\"nombre\", StringType(), True),\n",
    "    StructField(\"tipo\", StringType(), True),\n",
    "    StructField(\"alcohol\", DoubleType(), True),\n",
    "    StructField(\"acidez\", DoubleType(), True),\n",
    "    StructField(\"dulzor\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Datos de ejemplo\n",
    "datos = [\n",
    "    (\"Frutal Rosado\", \"joven\", 11.5, 3.2, 4.0),\n",
    "    (\"Dulce Mora\", \"joven\", 12.0, 3.5, 6.0),\n",
    "    (\"C√≠trico Blanco\", \"joven\", 10.8, 3.8, 2.5),\n",
    "    (\"Suave Tropical\", \"joven\", 11.2, 3.3, 5.0),\n",
    "    (\"Vino de Uva\", \"joven\", 12.2, 3.6, 3.5)\n",
    "]\n",
    "\n",
    "# Crear DataFrame\n",
    "df = spark.createDataFrame(data=datos, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c3fcc0e-d886-4985-86b5-371b23c63b22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aplicar describe\n",
    "# df.describe().show()\n",
    "\n",
    "# Aplicar summary (m√°s completo)\n",
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d3de3d-f7d6-4a86-8ac0-25e4e115e196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.data.summarize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4778e14-e54c-48c3-bcc5-64ec36c2ebc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31ab7bc9-7d8c-4491-96cf-598ae87b590a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81fe7f01-f47e-441b-aa26-4e06a9b7c482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "**.summary() (PySpark)**\n",
    "‚úÖ Se usa para obtener estad√≠sticas resumidas de todas las columnas (num√©ricas y no num√©ricas).\n",
    "‚úÖ Proporciona: 'count', 'mean', 'stddev', 'min', '25%', '50%', '75%', 'max'\n",
    "‚úÖ Incluye percentiles ‚Üí mejor que .describe().\n",
    "‚úÖ Requiere .show() para visualizar\n",
    "\n",
    "**.describe() (comparaci√≥n)(PySpark)**\n",
    "Solo da: 'count', 'mean', 'stddev', 'min', 'max'\n",
    "‚ùå No incluye percentiles\n",
    "‚ùå Menos completa ‚Üí no es suficiente para an√°lisis exploratorio completo\n",
    "\n",
    "**dbutils.data.summarize(df) (Databricks)**\n",
    "‚úÖ Abre una vista visual interactiva del DataFrame.\n",
    "‚úÖ Muestra autom√°ticamente:\n",
    "    Distribuci√≥n de cada columna (gr√°ficos)\n",
    "    Estad√≠sticas b√°sicas y tipo de variable\n",
    "    Recuentos para categor√≠as\n",
    "    Detecci√≥n de outliers\n",
    "‚úÖ No necesita show(), pero solo funciona dentro de notebooks Databricks.\n",
    "\n",
    "**display(df) (Databricks)**\n",
    "Muestra la tabla con paginaci√≥n.\n",
    "Permite elegir visualizaciones:\n",
    "\n",
    "‚úÖ Histogram\n",
    "‚úÖ Bar chart\n",
    "‚úÖ Line chart\n",
    "‚úÖ Box plot\n",
    "‚úÖ Scatter plot\n",
    "‚úÖ Map (si hay coordenadas)\n",
    "‚ùå No imprime estad√≠sticas num√©ricas autom√°ticamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6493e2bb-465e-4622-a992-2067c3ba7d40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Remove outliers from a Spark DataFrame based on standard deviation or IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fa9e127-fea0-4945-b847-0d506fa11701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Standard deviation\n",
    "\n",
    "Un valor es outlier si est√° fuera del rango: **Œº ¬± k ‚ãÖ œÉ**\n",
    "\n",
    "Donde:\n",
    "- Œº es la media\n",
    "- œÉ es la desviaci√≥n est√°ndar\n",
    "- k suele ser 2 o 3\n",
    "\n",
    "Pasos en PySpark:\n",
    "- Calcular mean y stddev con .agg()\n",
    "- Filtrar con .filter() los valores fuera del rango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "430e692f-79e6-4688-a66e-ef772be6e6d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, stddev\n",
    "\n",
    "mean_std = df.select(mean(\"price\").alias(\"mean\"), stddev(\"price\").alias(\"stddev\")).collect()[0]\n",
    "mean_val, stddev_val = mean_std[\"mean\"], mean_std[\"stddev\"]\n",
    "# Rango permitido\n",
    "lower_bound = mean_val - 2 * stddev_val\n",
    "upper_bound = mean_val + 2 * stddev_val\n",
    "filtered_df = df.filter((df[\"price\"] >= lower_bound) & (df[\"price\"] <= upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b71570f7-c68f-4526-99a3-a340ace05602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## IQR (Interquartile Range)\n",
    "\n",
    "Usa los cuartiles Q1, Q3 y el IQR:\n",
    "\n",
    "**IQR = Q3 ‚àí Q1**\n",
    "\n",
    "Outliers:\n",
    "- menores que Q1 ‚àí 1.5 ‚ãÖ IQR\n",
    "- mayores que Q3 + 1.5 ‚ãÖ IQR\n",
    "\n",
    "Pasos en PySpark:\n",
    "- Obtener cuartiles con .approxQuantile()\n",
    "- Calcular IQR\n",
    "- Filtrar fuera de los l√≠mites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50ef2d78-afb7-4fde-a025-2ec8c632eb46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Pyspark con .approxQuantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa8d8519-165f-4ec2-ab89-33449db9b853",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q1, q3 = df.approxQuantile(\"price\", [0.25, 0.75], 0.0)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "filtered_df = df.filter((df[\"price\"] >= lower_bound) & (df[\"price\"] <= upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf19b400-b3a0-4560-a033-ef08a5d7a951",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Pandas con .quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "803e464e-f9a3-469e-940f-14d2b6cfd7b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ejemplo en pandas \n",
    "\n",
    "Q1 = df['col'].quantile(0.25)\n",
    "Q3 = df['col'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "filtered_df = df[(df['col'] >= Q1 - 1.5 * IQR) & (df['col'] <= Q3 + 1.5 * IQR)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a195aa49-6c13-49e9-b495-7fb0fe1eb834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "¬øCu√°ndo usar cada m√©todo?\n",
    "\n",
    "| M√©todo                  | Cu√°ndo usar                                                                    |\n",
    "| ----------------------- | ------------------------------------------------------------------------------ |\n",
    "| **Desviaci√≥n est√°ndar** | Cuando la variable sigue una distribuci√≥n **normal o sim√©trica**               |\n",
    "| **IQR**                 | Cuando la variable tiene una distribuci√≥n **sesgada o con outliers** evidentes |\n",
    "\n",
    "**Nota:**\n",
    "\n",
    "- **Distribuci√≥n normal o sim√©trica:** Se representa gr√°ficamente como una curva en forma de campana\n",
    "- **Distribuci√≥n sesgada con outliers:** Una distribuci√≥n est√° sesgada cuando una de las colas de la curva es m√°s larga que la otra\n",
    "\n",
    "**Data Cleaning for Machine Learning** \n",
    "https://community.databricks.com/t5/technical-blog/data-cleaning-for-machine-learning/ba-p/95410#:~:text=Removing%20outliers%3A%20Using%20statistical%20methods,the%20overall%20impact%20of%20outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a091c30d-0a4a-4fd4-8c98-7dc42d34e6b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create visualizations for categorical or continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "857333d3-7760-4cf2-838c-56e976e76e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Con display(df) en notebooks\n",
    "M√©todo nativo de Databricks.\n",
    "\n",
    "Muestra una tabla interactiva ‚Üí puedes cambiar el tipo de gr√°fico desde el men√∫.\n",
    "Soporta:\n",
    "Bar chart\n",
    "Histogram\n",
    "Line chart\n",
    "Box plot\n",
    "Scatter plot\n",
    "Maps (si hay datos de coordenad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ec6d417-c153-4dab-bd77-6d3d3cd57fc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Con pandas API on Spark (pyspark.pandas) o conversi√≥n a Pandas\n",
    "Esto te permite usar .plot() como en pandas normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7b42b65-1238-485a-aca5-9049c75d575b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps\n",
    "psdf = df.pandas_api()\n",
    "psdf[\"age\"].plot(kind=\"hist\")\n",
    "\n",
    "####\n",
    "pdf = df.toPandas()\n",
    "pdf[\"price\"].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62b49a7e-57c6-42c9-ab35-55ffb7a3fad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos Clave\n",
    "\n",
    "| Tipo de variable | Ejemplo                    | Tipo de gr√°fico m√°s adecuado                    |\n",
    "| ---------------- | -------------------------- | ----------------------------------------------- |\n",
    "| **Categ√≥rica**   | g√©nero, pa√≠s, clase social | Bar chart, Pie chart, Count plot                |\n",
    "| **Continua**     | edad, precio, ingreso      | Histogram, Box plot, Density plot, Scatter plot |\n",
    "\n",
    "**Tipo de gr√°fico seg√∫n el objetivo**\n",
    "\n",
    "** - Para variables categ√≥ricas:**\n",
    "\n",
    "| Gr√°fico                            | Cu√°ndo usar                              | Funci√≥n                              |\n",
    "| ---------------------------------- | ---------------------------------------- | ------------------------------------ |\n",
    "| **Bar chart**                      | Comparar frecuencias de categor√≠as       | `display()` ‚Üí selecciona ‚ÄúBar chart‚Äù |\n",
    "| **Pie chart**                      | Comparar proporciones (pocas categor√≠as) | ‚ö†Ô∏è Pocas veces √∫til                  |\n",
    "| **Count plot** (en pandas/seaborn) | Contar ocurrencias                       | `sns.countplot()`                    |\n",
    "\n",
    "** - Para variables continuas:**\n",
    "\n",
    "| Gr√°fico          | Cu√°ndo usar                                       | Funci√≥n                                       |\n",
    "| ---------------- | ------------------------------------------------- | --------------------------------------------- |\n",
    "| **Histogram**    | Ver distribuci√≥n                                  | `display()` o `psdf[\"col\"].plot(kind=\"hist\")` |\n",
    "| **Box plot**     | Detectar outliers y asimetr√≠a                     | `display()` o `.plot(kind=\"box\")`             |\n",
    "| **Density plot** | Visualizar suavemente la forma de la distribuci√≥n | `sns.kdeplot()` (pandas/seaborn)              |\n",
    "| **Scatter plot** | Relaci√≥n entre dos variables num√©ricas            | `display(df)` ‚Üí ‚ÄúScatter‚Äù                     |\n",
    "\n",
    "\n",
    "https://docs.databricks.com/aws/en/visualizations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f15843-f871-4625-b516-e8e88efa9bf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27b2d66e-3fd6-423a-bbd5-d69279de77f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Compare two categorical or two continuous features using the appropriate method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0f62429-ff66-42b7-92c8-ee5d1161f8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Comparar dos variables categ√≥ricas\n",
    "\n",
    "Usa una tabla de contingencia y un test de chi-cuadrado si quieres evaluar independencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39d7545e-ceee-40b9-8b44-1b2530971a83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ejemplo: Comparar genero y compra_realizada\n",
    "\n",
    "Supongamos este DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a855355-6cc2-41bf-a172-a8a98487beb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"F\", \"S√≠\"), (\"M\", \"No\"), (\"F\", \"S√≠\"), (\"M\", \"S√≠\"),\n",
    "    (\"F\", \"No\"), (\"M\", \"No\"), (\"F\", \"S√≠\"), (\"M\", \"S√≠\")\n",
    "]\n",
    "df_spark = spark.createDataFrame(data, [\"genero\", \"compra_realizada\"])\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac55de10-2ebe-4104-8fb2-40308c01f10e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "a) Tabla de contingencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6d68d7e-e3d1-4d08-8b56-8b1138d3ef6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['genero'], df['compra_realizada'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64468187-3b0a-4cc1-bfeb-17bc2647727f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "b) Prueba de chi-cuadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b17b4df5-d473-47df-b159-f73508a734f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# una forma \n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "tabla = pd.crosstab(df['genero'], df['compra_realizada'])\n",
    "chi2, p, dof, expected = chi2_contingency(tabla)\n",
    "\n",
    "print(f\"Chi2: {chi2}, p-valor: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e649b55-567c-4903-8bc3-3b1a293279b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# con spark \n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "# Convertir texto a num√©rico\n",
    "indexer1 = StringIndexer(inputCol=\"genero\", outputCol=\"genero_idx\")\n",
    "indexer2 = StringIndexer(inputCol=\"compra_realizada\", outputCol=\"compra_idx\")\n",
    "\n",
    "df_indexed = indexer1.fit(df_spark).transform(df_spark)\n",
    "df_indexed = indexer2.fit(df_indexed).transform(df_indexed)\n",
    "\n",
    "# Crear vector de caracter√≠sticas\n",
    "assembler = VectorAssembler(inputCols=[\"genero_idx\"], outputCol=\"features\")\n",
    "df_features = assembler.transform(df_indexed)\n",
    "\n",
    "# Aplicar prueba chi-cuadrado\n",
    "chi_result = ChiSquareTest.test(df_features, \"features\", \"compra_idx\")\n",
    "chi_result.select(\"pValues\", \"degreesOfFreedom\", \"statistics\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "619a7399-ea44-41f2-bb2e-889711ea1e9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Si el p-valor < 0.05, hay relaci√≥n significativa entre las dos variables categ√≥ricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a64c82bb-3cba-4709-9155-c97c41345505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Comparar dos variables continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fea6ad0d-317b-468c-905d-05822242da6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Usa la correlaci√≥n (Pearson o Spearman).\n",
    "\n",
    "Ejemplo: Comparar edad vs ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d84fa2ef-2350-4f59-807e-8b6b69084fb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_continua = [\n",
    "    (25, 2200), (32, 2700), (47, 3500), (51, 4000), (38, 3000)\n",
    "]\n",
    "df_continuo = spark.createDataFrame(data_continua, [\"edad\", \"ingresos\"])\n",
    "df_continuo.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "384701fa-c74c-4ad1-a016-28c6c2808ed2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "a) Correlaci√≥n de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cc23094-2b58-473d-877d-0e5ed4f914a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pearson (lineal)\n",
    "df_continuo.stat.corr(\"edad\", \"ingresos\", method=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e02dd50-3f49-49a0-9da5-21dbd114de31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "b) Correlaci√≥n de Spearman (si no es lineal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb848e50-c4c2-4950-9f7e-8e51b4314f95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spearman (mon√≥tona)\n",
    "df_continuo.stat.corr(\"edad\", \"ingresos\", method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "965262d3-4ac7-467f-8d36-4b683dfb1507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "**Comparaci√≥n final de m√©todos**\n",
    "\n",
    "| Tipo de variables        | M√©todo recomendado           | Visualizaci√≥n                       |\n",
    "| ------------------------ | ---------------------------- | ----------------------------------- |\n",
    "| Categ√≥rica vs categ√≥rica | `crosstab`, chi-cuadrado     | Heatmap de frecuencias, stacked bar |\n",
    "| Continua vs continua     | Pearson/Spearman correlation | Scatter plot                        |\n",
    "\n",
    "**Conceptos clave que debes dominar para el examen**\n",
    "| Concepto                     | Detalle                                                               |\n",
    "| ---------------------------- | --------------------------------------------------------------------- |\n",
    "| `df.stat.crosstab()`         | √önico m√©todo de Spark para conteo entre categor√≠as                    |\n",
    "| `chi2_contingency()` (scipy) | No est√° en Spark nativo, pero evaluado conceptualmente                |\n",
    "| `df.stat.corr()`             | Aplica Pearson o Spearman en Spark                                    |\n",
    "| Pearson vs Spearman          | Pearson: lineal + normalidad<br>Spearman: ordinal o relaci√≥n mon√≥tona |\n",
    "\n",
    "| Funci√≥n clave                                | Qu√© hace                                                       |\n",
    "| -------------------------------------------- | -------------------------------------------------------------- |\n",
    "| `df.stat.crosstab(col1, col2)`               | Frecuencia entre dos columnas categ√≥ricas                      |\n",
    "| `df.stat.corr(col1, col2, method=\"pearson\")` | Correlaci√≥n de Pearson o Spearman                              |\n",
    "| `df.groupBy(...).count()`                    | Tambi√©n puede usarse para agrupaciones categ√≥ricas simples     |\n",
    "| `display(df)`                                | Permite hacer scatter plot para ver relaci√≥n entre 2 num√©ricas |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bce5b3bb-547a-4b63-a5ba-bc6c53a734a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Compare and contrast imputing missing values with the mean or median or mode value\n",
    "(Impute missing values with the mode, mean, or median value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cd03999-08a0-4a69-b943-3d60aac0926c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Imputar = reemplazar valores faltantes (nulls / NaNs) con alg√∫n valor que represente el resto de la distribuci√≥n.\n",
    "¬øPor qu√© imputar?\n",
    "\n",
    "- Muchos modelos no aceptan datos nulos.\n",
    "- Evita perder informaci√≥n si eliminas filas.\n",
    "- El m√©todo elegido afecta el sesgo y la varianza del modelo.\n",
    "\n",
    "| M√©todo               | Se aplica a                                 | Ventajas                                             | Desventajas                                      | Cu√°ndo usar                                                  |\n",
    "| -------------------- | ------------------------------------------- | ---------------------------------------------------- | ------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| **Mean (media)**     | Variables num√©ricas continuas               | F√°cil de calcular, mantiene media de la distribuci√≥n | Afectado por *outliers* y sesgo                  | Cuando la variable tiene distribuci√≥n **sim√©trica**          |\n",
    "| **Median (mediana)** | Variables num√©ricas continuas               | Robusta a *outliers* y sesgo                         | No conserva la media original                    | Cuando la variable tiene **distribuci√≥n sesgada o outliers** |\n",
    "| **Mode (moda)**      | Variables categ√≥ricas o num√©ricas discretas | Mejor para categor√≠as; representa el valor m√°s com√∫n | No siempre es representativo si hay varias modas | Cuando la variable es **categ√≥rica o discreta**              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e158f7d-87b3-41f9-b225-8d6194b97ba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Con .fillna() ‚Üí uso directo, manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fa7b7b0-43d6-4a0f-94f7-3ca1b30163c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.fillna({\"age\": 30, \"gender\": \"Male\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16e8e69b-0608-4f3e-854b-48e6584ac20d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Con Imputer (Spark ML) ‚Üí solo num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d6103ea-3f68-42f7-8493-e62f740910de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=[\"age\", \"income\"],\n",
    "    outputCols=[\"age_imputed\", \"income_imputed\"]\n",
    ").setStrategy(\"mean\")  # o \"median\"\n",
    "\n",
    "model = imputer.fit(df)\n",
    "df_imputed = model.transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07f2c3b9-e73f-4475-ab9b-9219e6c36482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "| Concepto                                    | Detalle clave                                         |\n",
    "| ------------------------------------------- | ----------------------------------------------------- |\n",
    "| `mode` no est√° en `Imputer`                 | Debes calcularlo manualmente y usar `.fillna()`       |\n",
    "| `median` es m√°s robusta que `mean`          | Se usa cuando hay outliers o datos sesgados           |\n",
    "| `mean` puede deformar la distribuci√≥n       | Especialmente en variables de ingresos, precios, etc. |\n",
    "| `Imputer` solo sirve con columnas num√©ricas | Para categ√≥ricas, debes usar otras t√©cnicas           |\n",
    "| Para variables categ√≥ricas                  | Solo **mode** es v√°lido como imputaci√≥n simple        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8afa4ea9-64fa-46c0-9a18-b90e98bfcfe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Use one-hot encoding for categorical features\n",
    "\n",
    "(Identify and explain the model types or data sets for which one-hot encoding is or is not\n",
    "appropriate.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63bf3ea3-02f9-4b72-9612-f2156ca2a24c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spark\n",
    "En Spark, el one-hot encoding se hace t√≠picamente en dos pasos con el m√≥dulo de MLlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e12eca64-c755-4efd-9e85-96dc9654f115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Indexar la columna categ√≥rica (convertir a n√∫meros)\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"color\", outputCol=\"color_index\")\n",
    "df_indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "# 2. Aplicar OneHotEncoder\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=[\"color_index\"], outputCols=[\"color_ohe\"])\n",
    "df_encoded = encoder.fit(df_indexed).transform(df_indexed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92c07703-e564-44c2-8dfd-d96b6cd8bd67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "| Punto                                                              | Explicaci√≥n                                                              |\n",
    "| ------------------------------------------------------------------ | ------------------------------------------------------------------------ |\n",
    "| Puede crear muchas columnas si la variable tiene muchas categor√≠as | ‚Üí Aumenta dimensionalidad y puede causar overfitting                     |\n",
    "| No es ideal para √°rboles de decisi√≥n o random forest en Spark      | ‚Üí Spark ML maneja los √≠ndices de categor√≠a directamente en estos modelos |\n",
    "| No funciona con valores nulos                                      | ‚Üí Debes imputar o filtrar primero                                        |\n",
    "\n",
    "\n",
    "‚úÖ √ösalo cuando:\n",
    "\n",
    "La variable es categ√≥rica sin orden (nominal)\n",
    "Usas modelos que no aceptan variables categ√≥ricas directamente, como regresi√≥n lineal, log√≠stica, redes neuronales\n",
    "\n",
    "‚ùå Evita si:\n",
    "\n",
    "Hay muchas categor√≠as ‚Üí usar feature hashing o embedding\n",
    "Est√°s usando tree-based models en Spark ML (como Random Forest o GBT) ‚Üí estos aceptan directamente √≠ndices de StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6105341-f8ea-4cdb-9185-74caa327e98a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify scenarios where log scale transformation is appropriate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a15eb58c-22fe-4fa0-8025-f30fc58c9a13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "¬øQu√© es una transformaci√≥n logar√≠tmica?\n",
    "Es una transformaci√≥n matem√°tica que aplica la funci√≥n logaritmo (por ejemplo, log base 10 o log natural) a una variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2482036c-5727-440f-bc94-600eee81dd57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import log\n",
    "df = df.withColumn(\"log_income\", log(df[\"income\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d70dc875-4174-4693-b239-17e8e4065f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Esta t√©cnica reduce la escala de los valores grandes y puede ayudar a que los datos cumplan mejor los supuestos de ciertos modelos.\n",
    "\n",
    "**Objetivo de la transformaci√≥n logar√≠tmica**\n",
    "- Reducir sesgo hacia la derecha (right-skewed data)\n",
    "- Estabilizar la varianza (heterocedasticidad)\n",
    "- Mejorar relaciones lineales entre variables\n",
    "- Permitir que el modelo aprenda mejor patrones exponenciales\n",
    "\n",
    "**Casos t√≠picos donde s√≠ es apropiado aplicar log**\n",
    "| Variable                                                  | Motivo                                                                     | Resultado esperado                         |\n",
    "| --------------------------------------------------------- | -------------------------------------------------------------------------- | ------------------------------------------ |\n",
    "| `income`, `house_price`, `sales`, `population`            | Datos muy **sesgados a la derecha**, con valores grandes y dispersi√≥n alta | Distribuci√≥n m√°s sim√©trica, m√°s linealidad |\n",
    "| `count` de eventos, como accesos por hora                 | Muchos ceros + valores extremos                                            | Compresi√≥n de valores grandes              |\n",
    "| Relaci√≥n exponencial (ej: y crece exponencialmente con x) | Mejora la linealidad                                                       | Permite usar regresi√≥n lineal              |\n",
    "\n",
    "**Casos donde NO debes aplicar log**\n",
    "| Caso                               | Por qu√© evitarlo                                |\n",
    "| ---------------------------------- | ----------------------------------------------- |\n",
    "| Valores ‚â§ 0 (negativos o ceros)    | No se puede aplicar log a 0 o n√∫meros negativos |\n",
    "| Variables ya normales o sim√©tricas | No necesitas transformar                        |\n",
    "| Variables categ√≥ricas              | No tiene sentido aplicar log                    |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c805582a-6c92-4e14-8048-5a78089ee470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "| Situaci√≥n                                                 | ¬øAplicar log? | Motivo                       |\n",
    "| --------------------------------------------------------- | ------------- | ---------------------------- |\n",
    "| Datos num√©ricos muy sesgados positivamente (right-skewed) | ‚úÖ S√≠          | Reduce la asimetr√≠a          |\n",
    "| Rangos muy amplios                                        | ‚úÖ S√≠          | Normaliza la escala          |\n",
    "| Exponenciales                                             | ‚úÖ S√≠          | Facilita modelado lineal     |\n",
    "| Ceros o negativos                                         | ‚ùå No          | log(x) indefinido para x ‚â§ 0 |\n",
    "| Categ√≥ricos                                               | ‚ùå No          | No tiene sentido             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcf430f1-ff6b-4cd6-b6c6-b7ad228833d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07f00971-3142-4a47-86d5-85b9d3596976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e28ca67-7b5a-477e-abfa-8e02ee0e8786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f64353d-9579-4353-a3d1-018044914e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Section 2: Data Processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
