{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76f8d560-1366-419d-9669-bea96be96cfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify the best practices of an MLOps strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efbb2026-163d-4dcd-a651-f85c8b18f4f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß† Conceptos clave que debes dominar\n",
    "\n",
    "| Categor√≠a                      | Buenas pr√°cticas                                                         | En Databricks‚Ä¶                                                            |\n",
    "| ------------------------------ | ------------------------------------------------------------------------ | ------------------------------------------------------------------------- |\n",
    "| **Ciclo de vida reproducible** | Usar pipelines reproducibles para entrenamiento, validaci√≥n y despliegue | Usa MLflow (tracking y proyectos) y notebooks versionados                 |\n",
    "| **Tracking de experimentos**   | Registrar autom√°ticamente m√©tricas, par√°metros y artefactos              | `mlflow.start_run()`, `mlflow.log_metric()`, etc.                         |\n",
    "| **Gesti√≥n de modelos**         | Registrar modelos con versi√≥n, etapa (`Staging`, `Production`) y alias   | Usa MLflow Model Registry (de Unity Catalog si es posible)                |\n",
    "| **Feature consistency**        | Reutilizar y centralizar features a trav√©s del **Feature Store**         | Usa `FeatureStoreClient`, tablas offline y online                         |\n",
    "| **Despliegue automatizado**    | Automatizar el paso de entrenamiento a producci√≥n mediante CI/CD         | Integra con repositorios Git + Jobs + REST APIs                           |\n",
    "| **Validaci√≥n de modelos**      | Validaci√≥n autom√°tica (unit tests, benchmarks) antes de promover         | Implementar validadores dentro de pipelines o con notebooks de validaci√≥n |\n",
    "| **Gobernanza y auditor√≠a**     | Control de accesos, trazabilidad de runs, versionado de c√≥digo/modelos   | Usa Unity Catalog y MLflow para registrar todo                            |\n",
    "| **Monitoreo post-despliegue**  | Monitorear performance de modelos en producci√≥n (drift, errores)         | Logs personalizados, uso de dashboards (ej. Databricks SQL)               |\n",
    "| **Promoci√≥n controlada**       | Promover modelos con alias (`Champion`, `Challenger`) y rollback         | Usa `set_registered_model_alias()` y validaci√≥n manual o autom√°tica       |\n",
    "| **Separaci√≥n de entornos**     | Desarrollo, staging y producci√≥n deben estar claramente separados        | Usa workspaces, clusters o UC para aislar entornos                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cf196b4-7a08-4183-9978-69667140bb2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "**Ciclo de vida del modelo**\n",
    "\n",
    "- MLOps automatiza: entrenamiento ‚Üí validaci√≥n ‚Üí registro ‚Üí despliegue ‚Üí monitoreo.\n",
    "- Siempre busca reproducibilidad ‚Üí versi√≥n de c√≥digo, datos, modelos y features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af78a4dd-ba1c-474f-8640-47eef9f528b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Best practices clave que debes conocer\n",
    "| Pr√°ctica                   | Qu√© recordar                                                  |\n",
    "| -------------------------- | ------------------------------------------------------------- |\n",
    "| **Tracking**               | Siempre registra m√©tricas, par√°metros y artefactos            |\n",
    "| **Versionado**             | Versiona modelo + c√≥digo + datos para trazabilidad            |\n",
    "| **Validaci√≥n**             | Usa m√©tricas + visuales + revisi√≥n humana antes de promover   |\n",
    "| **Feature Store**          | Garantiza consistencia entre training y serving               |\n",
    "| **Separaci√≥n de entornos** | Usa staging vs producci√≥n para minimizar riesgos              |\n",
    "| **Alias en modelos**       | `Champion` es el modelo activo, `Challenger` es el competidor |\n",
    "| **Gobernanza UC**          | Unity Catalog permite centralizar permisos y versiones        |\n",
    "\n",
    "## üÜö Diferencias comunes para memorizar\n",
    "| Concepto A                      | vs | Concepto B                 | Diferencia clave                                                         |\n",
    "| ------------------------------- | -- | -------------------------- | ------------------------------------------------------------------------ |\n",
    "| **MLflow Registry (workspace)** | vs | **Unity Catalog Registry** | El primero es local al workspace, el segundo es global y gobernado       |\n",
    "| **Promover modelos**            | vs | **Promover c√≥digo**        | Promover c√≥digo es para notebooks/scripts; modelos para flujos validados |\n",
    "| **Online features**             | vs | **Offline features**       | Online: baja latencia, serving; Offline: batch, training                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96a69500-eca0-48ed-971b-e2a23084d6a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify the advantages of using ML runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "556e4973-68eb-4648-a517-62ebf14170ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß† ¬øQu√© es un ML Runtime en Databricks?\n",
    "Un ML Runtime es una versi√≥n de entorno preconfigurado en Databricks que incluye:\n",
    "\n",
    "- Librer√≠as de machine learning m√°s usadas\n",
    "- Integraci√≥n lista con MLflow\n",
    "- Compatibilidad con GPU/TPU (seg√∫n instancia)\n",
    "- Compatibilidad con Spark para trabajo distribuido\n",
    "- Soporte para AutoML, Feature Store y Model Serving\n",
    "- Es como un \"conda env\" + Spark + MLflow listo para usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93ed82a1-1727-4918-9000-18604dc53869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "| **Ventaja**                                            | **Explicaci√≥n clara**                                                                                          | **T√©rmino clave a recordar** |\n",
    "| ------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------- | ---------------------------- |\n",
    "| üîå **Preconfigurado**                                  | Incluye `scikit-learn`, `xgboost`, `tensorflow`, `pytorch`, `mlflow`, etc. sin necesidad de instalaci√≥n manual | \"Listo para usar\"            |\n",
    "| üß© **Integraci√≥n total con MLflow**                    | No necesitas configurar tracking, UI, ni artifacts: ya viene integrado                                         | \"MLflow nativo\"              |\n",
    "| üß† **Soporte para AutoML**                             | AutoML en Databricks solo est√° disponible en ML Runtime                                                        | \"AutoML solo en ML Runtime\"  |\n",
    "| üß± **Compatible con Feature Store**                    | Solo disponible cuando usas ML Runtime en clusters de tipo `ml`                                                | \"Feature Store funcional\"    |\n",
    "| üöÄ **Optimizado para GPU y deep learning**             | Versiones de ML Runtime tienen builds con CUDA/cuDNN listos para usar                                          | \"GPU-ready\"                  |\n",
    "| üß™ **Entorno consistente para entrenar y servir**      | Permite que el modelo sea entrenado y desplegado en el mismo entorno (¬°menos errores!)                         | \"Same environment\"           |\n",
    "| üîí **Seguridad y mantenimiento oficial**               | Actualizado por Databricks con parches, dependencias seguras y validaci√≥n                                      | \"Mantenido por Databricks\"   |\n",
    "| ‚öôÔ∏è **Soporte para clusters compartidos y autoscaling** | Se puede usar con clusters din√°micos para batch y producci√≥n                                                   | \"Optimizado Spark + ML\"      |\n",
    "\n",
    "\n",
    "## Casos donde usar ML Runtime te da ventaja\n",
    "\n",
    "| Escenario                                                   | ¬øPor qu√© usar ML Runtime?                  |\n",
    "| ----------------------------------------------------------- | ------------------------------------------ |\n",
    "| Quieres hacer pruebas con AutoML r√°pido                     | Est√° disponible solo en ML Runtime         |\n",
    "| Quieres registrar m√©tricas en MLflow autom√°ticamente        | ML Runtime lo hace sin configuraci√≥n       |\n",
    "| Necesitas entrenar un modelo con PyTorch en GPU             | Hay ML Runtime con soporte para CUDA       |\n",
    "| Quieres servir un modelo con Databricks Model Serving       | ML Runtime garantiza compatibilidad        |\n",
    "| Usas Feature Store para features de entrenamiento y scoring | Solo funciona completamente con ML Runtime |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a9eb8b2-4b6b-4963-9cfb-21ffe865a3b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify how AutoML facilitates model/feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "791e1449-8385-430f-bd33-6b26e5516f3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© hace AutoML en Databricks?\n",
    "AutoML en Databricks automatiza gran parte del proceso de entrenamiento de modelos. En particular:\n",
    "\n",
    "- Prueba varios algoritmos (modelos) autom√°ticamente\n",
    "- Hace selecci√≥n de features relevantes\n",
    "- Aplica t√©cnicas de preprocesamiento y transformaci√≥n\n",
    "- Ajusta hiperpar√°metros con search space razonable\n",
    "- Genera un notebook reutilizable y reproducible\n",
    "\n",
    "\n",
    "## ¬øC√≥mo facilita la selecci√≥n de modelos y features?\n",
    "| Funci√≥n                                         | ¬øC√≥mo AutoML lo hace por ti?                                                                                                 | ¬øPor qu√© es √∫til?                                              |\n",
    "| ----------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- |\n",
    "| üß† **Prueba m√∫ltiples modelos autom√°ticamente** | Prueba `LogisticRegression`, `RandomForest`, `XGBoost`, etc., y compara m√©tricas como accuracy, ROC AUC, RMSE, etc.          | Ahorra tiempo; puedes elegir el mejor modelo sin codificar     |\n",
    "| üß™ **Selecciona features relevantes**           | Aplica t√©cnicas de importancia de variables (ej. `feature_importances_` o SHAP) y elimina features irrelevantes o colineales | Mejora performance y evita overfitting                         |\n",
    "| üßπ **Hace preprocesamiento autom√°tico**         | Imputaci√≥n de valores nulos, codificaci√≥n de variables categ√≥ricas, escalado de variables continuas                          | Evita errores comunes y garantiza inputs v√°lidos para modelos  |\n",
    "| üìä **Entrega m√©tricas comparativas**            | Genera tabla de runs con m√©tricas por modelo                                                                                 | Puedes analizar resultados y justificar la elecci√≥n del modelo |\n",
    "| üß± **Genera notebook con el mejor pipeline**    | El c√≥digo completo con steps, hiperpar√°metros, evaluaci√≥n, etc.                                                              | Puedes reproducir, mejorar o usar como base para producci√≥n    |\n",
    "\n",
    "\n",
    "## ¬øQu√© ocurre internamente?\n",
    "Cuando ejecutas:\n",
    "\n",
    "```python\n",
    "import databricks.automl\n",
    "summary = databricks.automl.classify(df, target_col=\"y\")\n",
    "```\n",
    "\n",
    "Databricks AutoML:\n",
    "\n",
    "- Detecta autom√°ticamente los tipos de columnas (num√©ricas, categ√≥ricas, fecha, etc.)\n",
    "- Realiza limpieza b√°sica: elimina columnas constantes, llena nulos, etc.\n",
    "- Hace ingenier√≠a de caracter√≠sticas (p. ej., one-hot encoding, extracci√≥n de fecha)\n",
    "- Corre m√∫ltiples modelos como:\n",
    "  - LogisticRegression\n",
    "  - LightGBM\n",
    "  - XGBoost\n",
    "  - RandomForest\n",
    "- Eval√∫a modelos con m√©tricas como f1, precision, roc_auc, etc.\n",
    "- Registra cada experimento en MLflow Tracking\n",
    "- Te devuelve:\n",
    "  - El mejor modelo\n",
    "  - Notebook del pipeline completo\n",
    "  - MLflow experiment con todas las ejecuciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f64eca88-5fe4-41ff-8da3-5997a7e76969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "| Pregunta t√≠pica                                                 | Respuesta esperada                                                    |\n",
    "| --------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| ¬øC√≥mo facilita AutoML la selecci√≥n de modelo?                   | Ejecuta m√∫ltiples modelos y compara m√©tricas autom√°ticamente          |\n",
    "| ¬øC√≥mo ayuda AutoML con la selecci√≥n de features?                | Eval√∫a la importancia de variables y elimina las irrelevantes         |\n",
    "| ¬øQu√© beneficio clave ofrece AutoML para el proceso de modelado? | Genera autom√°ticamente un notebook con el mejor pipeline reproducible |\n",
    "| ¬øD√≥nde puedes comparar el rendimiento de los modelos?           | En el experimento de MLflow que AutoML crea autom√°ticamente           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "343893bc-56fc-4aba-9666-cb7c4915c073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify the advantages AutoML brings to the model development process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4834a1d-e89f-485e-871f-a4fae2d5f01c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "| Etapa del proceso                                      | ¬øQu√© hace AutoML?                                                               | Ventaja clave                                             |\n",
    "| ------------------------------------------------------ | ------------------------------------------------------------------------------- | --------------------------------------------------------- |\n",
    "| üì¶ **Carga y limpieza de datos**                       | Detecta tipos de columnas, rellena nulos, descarta columnas vac√≠as o constantes | Reduce errores de entrada y tiempo de preparaci√≥n         |\n",
    "| üßº **Preprocesamiento autom√°tico**                     | Aplica one-hot encoding, escalado, transformaciones temporales, etc.            | Evita c√≥digo redundante y asegura inputs v√°lidos          |\n",
    "| üß† **Selecci√≥n autom√°tica de modelos y features**      | Corre m√∫ltiples algoritmos y selecciona el mejor seg√∫n m√©tricas                 | Acelera la exploraci√≥n y evita sesgos del analista        |\n",
    "| üß™ **Entrenamiento autom√°tico y optimizaci√≥n**         | Ajusta hiperpar√°metros con l√≥gica propia (ej. grid/random search)               | Ahorra tiempo y mejora la performance sin intervenci√≥n    |\n",
    "| üìä **Evaluaci√≥n autom√°tica**                           | Muestra comparaciones de m√©tricas: ROC AUC, RMSE, F1, etc.                      | Facilita decisiones sin necesidad de graficar manualmente |\n",
    "| üìù **Notebook generado autom√°ticamente**               | Entrega notebook 100‚ÄØ% editable y reproducible del mejor pipeline               | Acelera producci√≥n y aprendizaje del proceso              |\n",
    "| üîÑ **Integraci√≥n con MLflow**                          | Registra experimentos, par√°metros, m√©tricas, modelos y c√≥digo                   | Garantiza trazabilidad y reproducibilidad                 |\n",
    "| üöÄ **Escalabilidad con Spark y clusters distribuidos** | Corre en Spark clusters si el dataset es grande                                 | Permite manejar datasets grandes sin reescribir c√≥digo    |\n",
    "\n",
    "\n",
    "## Flashcards mentales para memorizar\n",
    "- AutoML reduce el tiempo de desarrollo ‚Üí automatiza desde limpieza hasta evaluaci√≥n\n",
    "- AutoML genera c√≥digo reutilizable ‚Üí notebook editable y listo para producci√≥n\n",
    "- AutoML integra con MLflow ‚Üí todo el tracking ya est√° hecho\n",
    "- AutoML escala en Spark ‚Üí puedes usarlo con datasets grandes\n",
    "- AutoML mejora productividad y precisi√≥n ‚Üí compara modelos con criterios objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd3bb8df-166e-45fb-8a02-b0cf582f572d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify the benefits of creating feature store tables at the account level in Unity Catalog in Databricks vs at the workspace level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "581d3bd7-d6f2-4ca7-98e7-637378c46680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Contexto: Qu√© es el Feature Store en Databricks\n",
    "El Feature Store de Databricks es un sistema centralizado para gestionar, versionar y reutilizar caracter√≠sticas (features) para modelos de ML. Permite:\n",
    "\n",
    "Definir, almacenar y documentar features.\n",
    "\n",
    "Compartir features entre equipos.\n",
    "\n",
    "Acceder a las features de forma consistente tanto en entrenamiento como en inferencia.\n",
    "\n",
    "## üîç Diferencia clave: Nivel de cuenta (Account-level / Unity Catalog) vs Nivel de workspace\n",
    "\n",
    "| Aspecto                   | Workspace-level Feature Store                                            | Unity Catalog (Account-level) Feature Store                                                                                |\n",
    "| ------------------------- | ------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Scope**                 | Solo accesible desde el workspace en que fue creado.                     | Accesible desde todos los workspaces que usen Unity Catalog dentro de la misma cuenta.                                     |\n",
    "| **Governanza**            | Gesti√≥n limitada por workspace.                                          | Control total a trav√©s de UC: roles, permisos, lineage, etc.                                                               |\n",
    "| **Reutilizaci√≥n**         | Limitada: features deben recrearse si se quieren usar en otro workspace. | Alta reutilizaci√≥n: features se centralizan y pueden compartirse globalmente.                                              |\n",
    "| **Seguridad y auditor√≠a** | Permisos locales del workspace.                                          | Seguridad avanzada con Unity Catalog, incluyendo **Auditing**, **Data Lineage**, y **Fine-grained Access Control (ABAC)**. |\n",
    "| **Escalabilidad**         | Dif√≠cil de escalar a nivel organizaci√≥n.                                 | Ideal para equipos grandes, entornos multicloud o multiworkspaces.                                                         |\n",
    "| **Colaboraci√≥n**          | Features aislados por workspace.                                         | Promueve la colaboraci√≥n entre equipos al compartir features desde un cat√°logo centralizado.                               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3545cc47-80b9-42ec-bc1a-d46a3de6351d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "- UC permite centralizar y reutilizar features entre m√∫ltiples workspaces.\n",
    "- UC mejora la seguridad, ya que se basa en acceso por Unity Catalog, no por configuraci√≥n local.\n",
    "- UC permite la trazabilidad y gobernanza completa del ciclo de vida de las features (qui√©n las cre√≥, qu√© modelos las usan, etc.).\n",
    "- UC es escalable a nivel de organizaci√≥n y multicloud.\n",
    "- Crear tablas de Feature Store en UC es m√°s adecuado para entornos de producci√≥n colaborativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15228ab6-a9e6-4436-82f4-d19310c1110a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create a feature store table in Unity Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbc3a281-1392-439b-a331-9cdee6d8de8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© es una Feature Store Table en Unity Catalog?\n",
    "Es una tabla de caracter√≠sticas reutilizable, registrada y versionada que puede ser accedida por diferentes equipos/proyectos a trav√©s de Unity Catalog, lo que permite mayor control, trazabilidad, reutilizaci√≥n y seguridad.\n",
    "\n",
    "## Requisitos previos\n",
    "Unity Catalog habilitado y configurado en el workspace.\n",
    "\n",
    "- Tener acceso a un metastore de Unity Catalog (nivel de cuenta, no solo de workspace).\n",
    "- Tener permisos para:\n",
    "- Crear esquemas (schemas) y tablas en Unity Catalog.\n",
    "- Acceder a datos fuentes.\n",
    "- Acceder a Feature Store (feature_store en Databricks Runtime for ML).\n",
    "\n",
    "## Conceptos que debes dominar\n",
    "Concepto\tDescripci√≥n\n",
    "| Concepto       | Descripci√≥n                                                               |\n",
    "| -------------- | ------------------------------------------------------------------------- |\n",
    "| Unity Catalog  | Sistema de control de acceso y gobernanza de datos a nivel de cuenta.     |\n",
    "| Feature Store  | Repositorio para almacenar y reutilizar caracter√≠sticas (features) de ML. |\n",
    "| Feature Lookup | Mecanismo para acceder a features registrados desde un modelo.            |\n",
    "| ML Runtime     | Databricks runtime optimizado para ML, incluye Feature Store client.      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05e34dc1-ceb6-42ea-836f-3d51a562f8f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üõ†Ô∏è Pasos para crear una tabla en Unity Catalog Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80996032-32c5-478b-9e0b-529c319dd1e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "from databricks.feature_store.entities.feature_table import FeatureTable\n",
    "\n",
    "# Instanciar el cliente\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "from pyspark.sql.functions import col\n",
    "df = spark.read.table(\"main.default.customer_data\").select(\"customer_id\", \"age\", \"income\")\n",
    "\n",
    "# Especificar el path en Unity Catalog: <catalog>.<schema>.<table>\n",
    "feature_table_name = \"main.marketing.customer_features\"\n",
    "\n",
    "# Crear la tabla\n",
    "fs.create_table(\n",
    "    name=feature_table_name,\n",
    "    primary_keys=[\"customer_id\"],\n",
    "    df=df,\n",
    "    schema=df.schema,\n",
    "    description=\"Customer demographic features for marketing models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec625c50-40e9-45d3-9325-3193cd3bbd33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Validaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad37e44b-c2dd-4edb-9944-25a54c72a95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fs.get_table(feature_table_name)\n",
    "\n",
    "# o \n",
    "\n",
    "spark.sql(\"DESCRIBE TABLE main.marketing.customer_features\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08b6c539-9692-4e90-b6dd-d13fc5b7b0ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øPor qu√© usar Unity Catalog en lugar de Feature Store a nivel de workspace?\n",
    "\n",
    "| Ventaja de Unity Catalog (nivel de cuenta) | Comparaci√≥n con nivel de workspace       |\n",
    "| ------------------------------------------ | ---------------------------------------- |\n",
    "| Reutilizaci√≥n entre workspaces             | Limitado a un solo workspace             |\n",
    "| Control de acceso centralizado             | Requiere ACLs individuales por workspace |\n",
    "| Integraci√≥n con Unity Lineage              | No disponible sin Unity Catalog          |\n",
    "| Versionado y trazabilidad                  | Manual o limitada                        |\n",
    "| Gobernanza de datos corporativa            | No apto para ambientes multi-equipo      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8f4e6ee-f144-45b8-bf84-10053f1c6115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1ff5eb3-859d-451d-8d84-9f071fe77507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Write data to a feature store table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b610b92c-ae6c-4c2d-9aed-2e77c5f56411",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. ¬øQu√© significa escribir datos a una Feature Store Table?\n",
    "Significa registrar un DataFrame de caracter√≠sticas (features) en una tabla del Feature Store. Esto permite:\n",
    "\n",
    "- Reutilizar los features en entrenamiento y producci√≥n.\n",
    "- Asegurar consistencia y trazabilidad.\n",
    "- Compartirlos con otros equipos y modelos.\n",
    "\n",
    "## 2. Requisitos previos\n",
    "El DataFrame debe tener columnas designadas como primary keys (claves √∫nicas por entidad).\n",
    "\n",
    "- Las columnas deben estar limpias y estables (sin datos faltantes ni altamente vol√°tiles).\n",
    "- Debes tener una tabla ya creada (o crearla en el momento con create_table()).\n",
    "\n",
    "## 3. M√©todos para escribir datos\n",
    "a) Usando write_table() para sobrescribir o a√±adir.\n",
    "\n",
    "b) Modos disponibles:\n",
    "- \"overwrite\": reemplaza toda la tabla.\n",
    "- \"merge\": actualiza los registros existentes y a√±ade nuevos.\n",
    "- \"append\": a√±ade nuevas filas sin afectar las existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fc567ac-d6f1-4b14-9503-c194f12ae4f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "fs.write_table(\n",
    "    name=\"main.catalog.schema.feature_table_name\",\n",
    "    df=features_df,\n",
    "    mode=\"overwrite\"  # o \"merge\" para a√±adir/actualizar\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "204635ca-a032-44d2-b5e0-6d9382d7d290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7264f56b-3b83-45df-8be4-9cd39517f966",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "## 4. ¬øQu√© incluye el DataFrame?\n",
    "Tu DataFrame debe contener:\n",
    "\n",
    "- Al menos una clave primaria (primary_keys).\n",
    "- Una columna por feature.\n",
    "- Idealmente una columna de timestamp si est√°s haciendo modelado temporal.\n",
    "\n",
    "Ejemplo \n",
    "\n",
    "| customer\\_id | timestamp  | avg\\_purchase | churn\\_score |\n",
    "| ------------ | ---------- | ------------- | ------------ |\n",
    "| 12345        | 2024-06-01 | 120.5         | 0.33         |\n",
    "\n",
    "##  5. Validaci√≥n autom√°tica de esquemas\n",
    "Al escribir en la tabla, Databricks valida que el esquema del DataFrame coincida con el esquema de la tabla.\n",
    "\n",
    "Si no coincide y el modo es \"merge\" o \"append\", lanza error.\n",
    "\n",
    "Puedes cambiar el esquema solo si usas \"overwrite\".\n",
    "\n",
    "## 6. Buenas pr√°cticas\n",
    "- No sobreescribas tablas si otros equipos las usan.\n",
    "- Usa \"merge\" para mantener un hist√≥rico sin perder datos.\n",
    "- Versiona tus features si cambian los c√°lculos o la l√≥gica.\n",
    "\n",
    "## 7. Ejemplo completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "259f75ce-0b50-4a3b-9cbd-108809421676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "# Supongamos que ya existe la tabla \"customer_features\"\n",
    "fs.write_table(\n",
    "    name=\"main.ml_catalog.features.customer_features\",\n",
    "    df=customer_features_df,\n",
    "    mode=\"merge\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8512819-2cfb-47bb-8dfe-ef2be8c85d5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Train a model with features from a feature store table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "541e769e-054c-48e2-b6ca-baac737536b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 1. ¬øPor qu√© usar la Feature Store para entrenar?\n",
    "- Reutilizaci√≥n de features: Evita duplicaci√≥n de l√≥gica de ingenier√≠a de variables.\n",
    "- Trazabilidad total: Puedes saber qu√© features us√≥ cada modelo.\n",
    "- Consistencia online-offline: Reduce el riesgo de skew en inferencia.\n",
    "- Auditor√≠a: Registra autom√°ticamente el origen de las caracter√≠sticas usadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32cf2ec6-f9fb-464c-b090-d915c783d671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Flujo general para entrenar un modelo desde la Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1df6e6f8-1978-4816-8af2-fd78b88e8003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "training_set = fs.create_training_set(\n",
    "    df=raw_data_df,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=\"main.catalog_name.feature_table_name\",\n",
    "            lookup_key=\"id_col\",\n",
    "            feature_names=[\"feature1\", \"feature2\"]\n",
    "        )\n",
    "    ],\n",
    "    label=\"target_col\",\n",
    "    exclude_columns=[\"id_col\"],\n",
    "    lookback_window=None,\n",
    ")\n",
    "\n",
    "training_df = training_set.load_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e173b720-26ff-412f-b076-a90b6a02f9ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Entrenamiento con un modelo\n",
    "Una vez cargado training_df, puedes entrenar tu modelo con cualquier framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84e430d5-9c08-4ab7-86a5-93c3ad81682d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(training_df.drop(columns=\"target_col\"), training_df[\"target_col\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63a83a7f-a373-45c9-9f49-6d9f2644bece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Tambi√©n puedes usar MLflow para loggear el modelo y asociar los features utilizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3190dc7-d407-4376-8e5c-a2dade20b1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model.fit(...)\n",
    "    fs.log_model(\n",
    "        model=model,\n",
    "        artifact_path=\"model\",\n",
    "        flavor=mlflow.sklearn,\n",
    "        training_set=training_set,\n",
    "        registered_model_name=\"mi_modelo_uc\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8db278e-fb92-4744-a404-dc2f0d8232dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Consideraciones t√©cnicas\n",
    "\n",
    "Puedes hacer lookup a m√∫ltiples feature tables.\n",
    "\n",
    "La columna lookup_key debe estar en tu raw_data_df.\n",
    "\n",
    "create_training_set tambi√©n acepta filtros (timestamp_lookup_key, lookback_window, etc.) para datos temporales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f554a3b-14bb-4374-aa1f-f88e36f8694f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "### Memoriza esto para el examen:\n",
    "\n",
    "| Concepto                | Detalle                                                         |\n",
    "| ----------------------- | --------------------------------------------------------------- |\n",
    "| `FeatureStoreClient()`  | Cliente para interactuar con feature store                      |\n",
    "| `create_training_set()` | Crea el conjunto de entrenamiento uniendo features con raw data |\n",
    "| `FeatureLookup()`       | Define c√≥mo buscar los features                                 |\n",
    "| `log_model()`           | Guarda el modelo y su dependencia con la feature store          |\n",
    "| Beneficios              | Reutilizaci√≥n, auditabilidad, consistencia y trazabilidad       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe13cc42-cda4-4bbb-bdea-0d2e0c3cd734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Score a model using features from a feature store table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10f5d598-0cf5-4cc7-b8cc-7a31f95542af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© significa \"score a model using features from a feature store table\"?\n",
    "Es el proceso de cargar un modelo registrado con la Feature Store, y usarlo para hacer predicciones sobre nuevos datos, combinando estos datos con las caracter√≠sticas registradas en la Feature Store.\n",
    "\n",
    "## Flujo general de scoring (inferencia)\n",
    "Tienes un modelo entrenado con FeatureStoreClient.log_model(...).\n",
    "\n",
    "Quieres hacer predicciones con datos nuevos (raw_input_df).\n",
    "\n",
    "Usas fs.score_batch(...) para obtener las predicciones, utilizando los features ya registrados.\n",
    "\n",
    "## Paso a paso con ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc1565f4-9ab1-4606-b8e9-f7832597eb41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "# 1. Crear el cliente\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "# 2. Preparar los datos nuevos para hacer scoring\n",
    "raw_input_df = spark.read.table(\"default.nuevos_datos\")\n",
    "\n",
    "# 3. Scoring usando el modelo y las features\n",
    "predicciones = fs.score_batch(\n",
    "    model_uri=\"models:/nombre_modelo/1\",\n",
    "    df=raw_input_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94c6bb9b-13d4-48cc-a588-40c6e4f7e0d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "‚úÖ model_uri puede ser una versi√≥n espec√≠fica (models:/modelo/1) o el √∫ltimo (models:/modelo/latest).\n",
    "\n",
    "## ‚úÖ ¬øQu√© hace internamente score_batch?\n",
    "Une tu raw_input_df con las feature tables usadas durante el entrenamiento.\n",
    "\n",
    "Aplica las mismas transformaciones de features que se usaron para entrenar el modelo.\n",
    "\n",
    "Devuelve un nuevo DataFrame con las predicciones.\n",
    "\n",
    "## ‚ö†Ô∏è Requisitos importantes\n",
    "\n",
    "| Requisito                   | Detalle                                                                                                                      |\n",
    "| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Modelo registrado           | Debe estar registrado con `fs.log_model(...)`, incluyendo su `training_set`.                                                 |\n",
    "| Columnas de lookup          | `raw_input_df` debe tener las claves necesarias para hacer join con las feature tables.                                      |\n",
    "| No puedes usar sklearn puro | `score_batch()` funciona con modelos registrados mediante Feature Store, no con modelos sklearn que registraste manualmente. |\n",
    "\n",
    "## üß† Memoriza esto para el examen\n",
    "\n",
    "| Elemento clave       | Descripci√≥n                                                                                 |\n",
    "| -------------------- | ------------------------------------------------------------------------------------------- |\n",
    "| `score_batch()`      | Usa modelo y Feature Store para generar predicciones                                        |\n",
    "| `model_uri`          | Ruta al modelo en el registry (`models:/mi_modelo/1`)                                       |\n",
    "| `df`                 | DataFrame con claves para lookup de features                                                |\n",
    "| Requiere `log_model` | Solo funciona si el modelo se registr√≥ con `fs.log_model()` y tiene `training_set` asociado |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aac6a162-27af-4e16-bfb7-38785fb76269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Describe the differences between online and offline feature tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b780ebf-fae5-4014-8a15-4560b84b4b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîç Diferencias entre tablas de caracter√≠sticas online y offline\n",
    "\n",
    "| Caracter√≠stica                                    | **Feature Tables Offline**                              | **Feature Tables Online**                                 |\n",
    "| ------------------------------------------------- | ------------------------------------------------------- | --------------------------------------------------------- |\n",
    "| **Uso principal**                                 | Entrenamiento y batch scoring (predicciones por lotes)  | Serving de modelos en tiempo real (predicciones online)   |\n",
    "| **Velocidad de acceso**                           | M√°s lento (no optimizado para baja latencia)            | Muy r√°pido (optimizado para baja latencia)                |\n",
    "| **Frecuencia de actualizaci√≥n**                   | Menos frecuente, programado (por lotes)                 | Frecuente, a menudo en tiempo real o casi en tiempo real  |\n",
    "| **D√≥nde se almacena**                             | Delta Lake (almacenamiento en la nube)                  | Tiendas de baja latencia (ej. Redis, Cassandra, etc.)     |\n",
    "| **Integraci√≥n con Databricks Feature Store**      | Totalmente soportado para entrenamiento y batch scoring | Necesita configuraci√≥n adicional para online serving      |\n",
    "| **Casos de uso**                                  | - Entrenar modelos<br>- Validaci√≥n<br>- Batch scoring   | - Recomendaciones en tiempo real<br>- Detecci√≥n de fraude |\n",
    "| **Versionamiento de caracter√≠sticas**             | S√≠, se versionan autom√°ticamente                        | No necesariamente, puede depender del sistema externo     |\n",
    "| **Consistencia de datos (training/serving skew)** | Posibilidad de **skew** si no se sincronizan bien       | Reduce el skew si se gestiona correctamente               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb3c998e-52e0-4dc6-b329-248eb9399b40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "- Offline = Entrenamiento, Online = Serving en tiempo real.\n",
    "\n",
    "- Las tablas offline est√°n en Delta Lake, las online en almacenes de baja latencia.\n",
    "\n",
    "- Las tablas online ayudan a minimizar el training/serving skew si se mantienen sincronizadas.\n",
    "\n",
    "- Usar ambas puede ser necesario para una soluci√≥n de MLOps completa: entrenas con offline, sirves con online.\n",
    "\n",
    "- Databricks Feature Store integra nativamente el uso de offline tables, y puede configurarse para servir online features mediante otros servicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27ee4555-65a0-4967-b0b1-d27cd7a8976c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify the best run using the MLflow Client API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f24374af-1f7d-495b-b89c-f115ff14d637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Enfoque con la API MLflow\n",
    "1. Usando mlflow.search_runs()\n",
    "Este m√©todo es f√°cil de usar y devuelve un pandas DataFrame con todos los runs de un experimento. Luego puedes ordenar y filtrar seg√∫n m√©trica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecac45df-eb0c-4726-9a5c-4aa1caaf39a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "runs = mlflow.search_runs(experiment_ids=[exp_id])\n",
    "best = runs.sort_values(\"metrics.accuracy\", ascending=False).iloc[0]\n",
    "best_run_id = best.run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af534647-7a82-4f21-9a7b-5110af189967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Este enfoque funciona bien si est√°s usando MLflow en Databricks y quieres obtener r√°pidamente el run con la m√©trica m√°s alta.\n",
    "mlflow.org\n",
    "Databricks\n",
    "\n",
    "## 2. Usando el cliente de bajo nivel MlflowClient.search_runs()\n",
    "Es √∫til cuando necesitas m√°s control o paginaci√≥n, pero puede requerir iterar p√°ginas manualmente.\n",
    "Preferible usar mlflow.search_runs() ya que devuelve todos los resultados directamente.\n",
    "\n",
    "## üìå Ejemplo completo en un notebook de Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bb6d3c8-e55b-47fa-aee1-7e09db6d25e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Si solo conoces el nombre del experimento\n",
    "exp = MlflowClient().get_experiment_by_name(experiment_name)\n",
    "exp_id = exp.experiment_id\n",
    "\n",
    "# Extraer todos los runs del experimento\n",
    "runs = mlflow.search_runs(experiment_ids=[exp_id])\n",
    "\n",
    "# Encontrar el mejor run seg√∫n la m√©trica deseada\n",
    "best = runs.sort_values(\"metrics.f1_score\", ascending=False).iloc[0]\n",
    "best_run_id = best.run_id\n",
    "best_metric = best[\"metrics.f1_score\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6500e8bb-e9c1-4e06-b0d1-11d591419ed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "| Elemento                                            | Uso                                                    |\n",
    "| --------------------------------------------------- | ------------------------------------------------------ |\n",
    "| `mlflow.search_runs(...)`                           | Devuelve todos los runs como pandas DataFrame.         |\n",
    "| `.sort_values(\"metrics.<nombre>\", ascending=False)` | Ordena para encontrar el mejor run seg√∫n la m√©trica.   |\n",
    "| `.iloc[0]`                                          | Selecciona el top 1.                                   |\n",
    "| `MlflowClient().search_runs()`                      | Variante de bajo nivel, requiere manejo de paginaci√≥n. |\n",
    "| M√©trica clave (accuracy, f1\\_score, rmse, etc.)     | Define qu√© ‚Äúmejor run‚Äù buscas.                         |\n",
    "| Paciencia con paginaci√≥n si hay muchos runs         | `mlflow.search_runs()` maneja mejor paginaci√≥n.        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a072e1e-ad4d-4ef5-a202-3380c4208b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Manually log metrics, artifacts, and models in an MLflow Run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe149c40-6f3b-46d9-b4b6-a9efbdd66542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ ¬øQu√© es un MLflow Run?\n",
    "Es una ejecuci√≥n registrada dentro de MLflow que guarda informaci√≥n sobre un experimento: m√©tricas, par√°metros, artefactos (como modelos o gr√°ficos), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b81d85f-0ff6-4b8d-b73c-0c3eaec5fa38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "| Elemento             | M√©todo en MLflow                                                            | Descripci√≥n breve                                        |\n",
    "| -------------------- | --------------------------------------------------------------------------- | -------------------------------------------------------- |\n",
    "| Iniciar un run       | `mlflow.start_run()`                                                        | Inicia un bloque de ejecuci√≥n para registrar informaci√≥n |\n",
    "| Registrar par√°metros | `mlflow.log_param(\"param\", value)`                                          | Guarda hiperpar√°metros                                   |\n",
    "| Registrar m√©tricas   | `mlflow.log_metric(\"metric\", value)`                                        | Guarda valores de rendimiento (accuracy, RMSE, etc.)     |\n",
    "| Registrar artefactos | `mlflow.log_artifact(\"path\")`                                               | Guarda archivos generados (im√°genes, logs, etc.)         |\n",
    "| Registrar modelos    | `mlflow.sklearn.log_model()`                                                | Guarda el modelo entrenado en formato serializable       |\n",
    "| Finalizar run        | Autom√°ticamente al salir del bloque `with`, o manual con `mlflow.end_run()` |       \n",
    "\n",
    "## üí° Ejemplo pr√°ctico (en Databricks con scikit-learn)                                                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d6e2ef0-26f0-4088-ad65-24bc1d834e55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Datos\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Entrenar modelo\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# M√©tricas\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "# Run MLflow\n",
    "with mlflow.start_run(run_name=\"iris_rf_model\") as run:\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # Guardar artefacto adicional (si existiera, por ejemplo una imagen)\n",
    "    # mlflow.log_artifact(\"path_to_file\")\n",
    "\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "868dffe2-f926-4277-abd6-f42312d63637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß† ¬øQu√© debes dominar?\n",
    "- El uso de log_param, log_metric, log_artifact, y log_model.\n",
    "\n",
    "- Saber que log_artifact espera un archivo en disco, no un objeto.\n",
    "\n",
    "- Reconocer que los runs se agrupan en experimentos (mlflow.set_experiment(\"nombre\")).\n",
    "\n",
    "- Puedes usar el MLflow UI para visualizar el run, el modelo y los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ee7c761-db7e-48e6-9eef-aac5ec74da1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify information available in the MLFlow UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d54dfaae-0e83-46a0-a176-9058629bf05e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ 1. Informaci√≥n disponible en la MLflow UI\n",
    "La interfaz gr√°fica de MLflow en Databricks o en instalaciones propias te permite rastrear y visualizar m√∫ltiples aspectos de tus experimentos. Estos son los elementos que puedes identificar desde la UI:\n",
    "\n",
    "## üß™ Experimentos (Experiments)\n",
    "Un experimento agrupa m√∫ltiples ejecuciones (runs).\n",
    "\n",
    "Se pueden crear desde el UI, notebook o c√≥digo.\n",
    "\n",
    "Desde la pesta√±a de Experimentos, puedes:\n",
    "\n",
    "Filtrar ejecuciones por nombre, par√°metro, m√©trica, etiqueta, etc.\n",
    "\n",
    "Comparar m√∫ltiples ejecuciones lado a lado.\n",
    "\n",
    "## üîÅ Ejecuciones (Runs)\n",
    "Cada ejecuci√≥n representa una instancia de entrenamiento o prueba de un modelo.\n",
    "\n",
    "| Categor√≠a                    | Elementos disponibles en UI                                                       |\n",
    "| ---------------------------- | --------------------------------------------------------------------------------- |\n",
    "| **Parametros** (`params`)    | Hiperpar√°metros usados en el modelo. Ejemplo: `max_depth=3`, `learning_rate=0.01` |\n",
    "| **M√©tricas** (`metrics`)     | Resultados cuantitativos, como `accuracy`, `rmse`, `log_loss`, etc.               |\n",
    "| **Artefactos** (`artifacts`) | Archivos generados: modelo entrenado, gr√°ficos, CSVs, visualizaciones, etc.       |\n",
    "| **Etiquetas** (`tags`)       | Informaci√≥n adicional como autor, versi√≥n del dataset, tipo de modelo.            |\n",
    "\n",
    "\n",
    "## üì¶ Modelos (Registered Models)\n",
    "Puedes ver los modelos registrados y sus versiones.\n",
    "\n",
    "Incluye:\n",
    "\n",
    "Detalles del modelo (nombre, descripci√≥n).\n",
    "\n",
    "Historial de versiones.\n",
    "\n",
    "Estado del modelo: Staging, Production, Archived.\n",
    "\n",
    "## üìà Visualizaci√≥n de m√©tricas\n",
    "Puedes ver c√≥mo cambia una m√©trica (ej. accuracy) a trav√©s de m√∫ltiples ejecuciones.\n",
    "\n",
    "Herramientas:\n",
    "\n",
    "Gr√°ficas de dispersi√≥n.\n",
    "\n",
    "Filtrado por condiciones (ej. learning_rate > 0.01).\n",
    "\n",
    "Comparaciones entre ejecuciones.\n",
    "\n",
    "## üîÑ Comparaci√≥n de ejecuciones\n",
    "Selecciona m√∫ltiples ejecuciones y usa la herramienta Compare.\n",
    "\n",
    "Te permite:\n",
    "\n",
    "Comparar m√©tricas y par√°metros.\n",
    "\n",
    "Identificar cu√°l ejecuci√≥n tiene mejor desempe√±o.\n",
    "\n",
    "## ‚è≥ Tiempos\n",
    "Fecha y hora de inicio y fin de la ejecuci√≥n.\n",
    "\n",
    "Duraci√≥n total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e101af8-4801-45a1-90f0-2822792a9349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves\n",
    "\n",
    "| Elemento       | Qu√© debes recordar                                                                         |\n",
    "| -------------- | ------------------------------------------------------------------------------------------ |\n",
    "| `params`       | Hiperpar√°metros del modelo                                                                 |\n",
    "| `metrics`      | Indicadores de desempe√±o (ej. accuracy)                                                    |\n",
    "| `artifacts`    | Archivos generados (modelo, visualizaciones)                                               |\n",
    "| `tags`         | Informaci√≥n adicional, como nombre del experimento                                         |\n",
    "| UI te permite  | Comparar ejecuciones, ver gr√°ficas, registrar modelos                                      |\n",
    "| Model Registry | Donde se gestionan versiones de modelos y se les asignan estados (`Staging`, `Production`) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4ec1609-78d7-4def-8972-b5b20bbcdada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register a model using the MLflow Client API in the Unity Catalog registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bda99363-f392-43a0-b4ad-1b197b0d62a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70e8aa7d-98e2-4436-9659-a446c452b739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify benefits of registering models in the Unity Catalog registry over the workspace registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e3caa94-1331-4b7b-acc1-2628d9ac8d6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "320df46b-44d2-4005-9a6b-9eeb1d3e671e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify scenarios where promoting code is preferred over promoting models and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04824651-3103-45fd-ba42-ba030b786be0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac30f65c-abb9-4bc9-aa09-3197c294b4cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Set or remove a tag for a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd0caa81-b195-43ae-bd26-981173a3798a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfcc565b-7aa1-4ce7-aaf7-7c6466295b52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Promote a challenger model to a champion model using aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8efa090a-4def-4a9d-adcf-b0f234ead3cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos claves"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Section 1: Databricks Machine Learning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
