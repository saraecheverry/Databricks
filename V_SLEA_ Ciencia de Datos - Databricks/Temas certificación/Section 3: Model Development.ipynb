{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ceabd86c-a7f9-4d74-8462-651485226082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Use ML foundations to select the appropriate algorithm for a given model scenario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b3120c5-2f62-43aa-8f8c-b1c5e37c17f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Tipo de problema: clasificaci√≥n vs regresi√≥n\n",
    "Clasificaci√≥n (binaria o multiclase):\n",
    "\n",
    "¬øPredices categor√≠as o etiquetas? (Ej: churn: s√≠/no)\n",
    "\n",
    "Algoritmos t√≠picos: Logistic Regression, Decision Tree, Random Forest, GBTClassifier\n",
    "\n",
    "Regresi√≥n:\n",
    "\n",
    "¬øPredices una variable num√©rica continua? (Ej: predicci√≥n de precio)\n",
    "\n",
    "Algoritmos t√≠picos: Linear Regression, Decision Tree Regressor, GBTRegressor, XGBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed3bdeaa-45d6-46d7-858c-8c3984b3da9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Algoritmos frecuentes y cu√°ndo usarlos\n",
    "\n",
    "| Algoritmo                        | Tipo          | Cu√°ndo usarlo                                        | Pros                                      | Contras                                   |\n",
    "| -------------------------------- | ------------- | ---------------------------------------------------- | ----------------------------------------- | ----------------------------------------- |\n",
    "| **Logistic Regression**          | Clasificaci√≥n | Problemas lineales, interpretabilidad alta           | R√°pido, interpretable                     | No captura relaciones no lineales         |\n",
    "| **Linear Regression**            | Regresi√≥n     | Relaciones lineales simples                          | Sencillo, explicable                      | Poco flexible ante relaciones no lineales |\n",
    "| **Decision Tree**                | Ambos         | Datos interpretables, no lineales, sin normalizaci√≥n | No requiere escalado, f√°cil de visualizar | Propenso a overfitting                    |\n",
    "| **Random Forest**                | Ambos         | Datos complejos, buena generalizaci√≥n                | Robusto, mejora overfitting               | Menos interpretable, m√°s lento            |\n",
    "| **GBT (Gradient-Boosted Trees)** | Ambos         | Alta precisi√≥n, datos desbalanceados                 | Mejor rendimiento que RF en muchos casos  | Entrenamiento lento, sensible a ruido     |\n",
    "| **XGBoost**                      | Ambos         | Escenarios con muchos datos y features importantes   | Precisi√≥n alta, regularizaci√≥n integrada  | Requiere m√°s tuning, menos interpretable  |\n",
    "\n",
    "## Factores que influyen en la elecci√≥n del modelo\n",
    "\n",
    "| Factor                         | Consideraci√≥n                                                                    |\n",
    "| ------------------------------ | -------------------------------------------------------------------------------- |\n",
    "| **Tama√±o del dataset**         | GBT y XGBoost funcionan mejor con muchos datos                                   |\n",
    "| **Balance de clases**          | Algoritmos como GBT y Logistic soportan `class_weight`; Random Forest es robusto |\n",
    "| **Interpretabilidad**          | Preferir Logistic o Decision Tree                                                |\n",
    "| **Requerimientos de tiempo**   | Logistic y Linear son r√°pidos; GBT y XGBoost pueden tardar                       |\n",
    "| **Relaci√≥n entre variables**   | Si es no lineal ‚Üí evitar regresiones lineales simples                            |\n",
    "| **Colinealidad / redundancia** | XGBoost y √°rboles manejan mejor variables redundantes                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc99ba60-0216-4da1-8572-4acfacf05c65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "- **¬øQu√© es normalizaci√≥n?**\n",
    "En muchos algoritmos (como regresiones o redes neuronales), necesitas que tus features num√©ricos est√©n en una misma escala (por ejemplo, entre 0 y 1), usando t√©cnicas como:\n",
    "\n",
    "StandardScaler: para que cada feature tenga media 0 y desviaci√≥n est√°ndar 1\n",
    "\n",
    "MinMaxScaler: para escalar entre un rango definido (usualmente 0 a 1)\n",
    "\n",
    "- **Qu√© es \"ruido\"**\n",
    "| Tipo de ruido              | Ejemplo                                     | Impacto                                                   |\n",
    "| -------------------------- | ------------------------------------------- | --------------------------------------------------------- |\n",
    "| **Errores en los datos**   | Registros con etiquetas incorrectas o typos | GBT puede aprender a \"explicar\" errores que no se repiten |\n",
    "| **Outliers**               | Valores extremos en variables num√©ricas     | Puede crear divisiones innecesarias solo para esos casos  |\n",
    "| **Variables irrelevantes** | Features que no aportan al target           | GBT puede intentar exprimirles se√±al que no existe        |\n",
    "| **Variabilidad aleatoria** | Efectos que no se repetir√°n en nuevos datos | Aprendidos como si fueran patrones reales                 |\n",
    "\n",
    "- **Qu√© es regularizaci√≥n\"**\n",
    "\n",
    "| Concepto       | Explicaci√≥n simple                                                                       |\n",
    "| -------------- | ---------------------------------------------------------------------------------------- |\n",
    "| Regularizaci√≥n | Penalizar la complejidad del modelo para evitar que aprenda demasiado                    |\n",
    "| ¬øCu√°ndo?       | Cuando hay riesgo de overfitting                                                         |\n",
    "| ¬øC√≥mo?         | Penalizando coeficientes (regresi√≥n) o limitando profundidad/tama√±o del modelo (√°rboles) |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "478c2ea7-a65a-4a6b-b13d-5643a3c1d453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify methods to mitigate data imbalance in training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e0d35a4-49fc-4e23-89fc-680ee2063533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© es un dataset desbalanceado?\n",
    "\n",
    "| Problema            | Clase mayoritaria      | Clase minoritaria     |\n",
    "| ------------------- | ---------------------- | --------------------- |\n",
    "| Detecci√≥n de fraude | Transacciones normales | Fraudes               |\n",
    "| Churn prediction    | Clientes activos       | Clientes que cancelan |\n",
    "| Diagn√≥stico m√©dico  | Pacientes sanos        | Casos positivos       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af2b1e7d-f1a9-415e-a561-0083157d96fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## T√©cnicas para mitigar el desbalance\n",
    "\n",
    "### 1. Modificaci√≥n del dataset\n",
    "\n",
    "| T√©cnica           | Qu√© hace                                           | Cu√°ndo usarla                                                | Herramientas         |\n",
    "| ----------------- | -------------------------------------------------- | ------------------------------------------------------------ | -------------------- |\n",
    "| **Undersampling** | Quita ejemplos de la clase mayoritaria             | Cuando hay muchos datos disponibles                          | `RandomUnderSampler` |\n",
    "| **Oversampling**  | Duplica ejemplos de la clase minoritaria           | Cuando se tiene pocos datos de esa clase                     | `RandomOverSampler`  |\n",
    "| **SMOTE**         | Genera ejemplos sint√©ticos de la clase minoritaria | Cuando quieres mejorar la diversidad de la clase minoritaria | `imblearn.SMOTE`     |\n",
    "\n",
    "\n",
    "### 2. Modificaci√≥n del modelo (ajuste de pesos)\n",
    "\n",
    "En vez de tocar los datos, puedes ajustar el modelo para que:\n",
    "\n",
    "- Le d√© m√°s peso a los errores en la clase minoritaria\n",
    "- Algunas implementaciones permiten class_weight='balanced'\n",
    "\n",
    "| Modelo                           | ¬øSoporta class\\_weight?      |\n",
    "| -------------------------------- | ---------------------------- |\n",
    "| Logistic Regression              | ‚úÖ S√≠                         |\n",
    "| Decision Tree / RF / GBT (Spark) | ‚úÖ S√≠, con `weightCol`        |\n",
    "| XGBoost                          | ‚úÖ S√≠, con `scale_pos_weight` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd7522c7-5056-46d3-bd4e-acf3b3798e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "Elegir m√©tricas adecuadas cuando el dataset est√° desbalanceado:\n",
    "\n",
    "| Evitar                  | Usar en su lugar              |\n",
    "| ----------------------- | ----------------------------- |\n",
    "| ‚ùå Accuracy              | ‚úÖ F1-score, Precision, Recall |\n",
    "| ‚ùå ROC-AUC (en extremos) | ‚úÖ Precision-Recall Curve      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "605d62e2-f7ab-49a7-b12d-e76c5cc569ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ba4a627-b2f4-426c-9919-a55e835977c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#  Compare estimators and transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "598aa3fb-1d78-481c-9872-7d72b025026e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- pipeline en sklearn https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html \n",
    "- Transformer rm sklearn https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8ac4b1d-e05f-4d97-b8d1-7c53044bafd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© es un Estimator?\n",
    "\n",
    "Un Estimator es cualquier objeto que aprende a partir de los datos. Su funci√≥n principal es:\n",
    "Aplicar .fit() sobre un DataFrame para producir un Transformer.\n",
    "\n",
    "üí° Ejemplo: LogisticRegression, StandardScaler, PCA, StringIndexer, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "973f8694-b97a-463b-ac2c-3e82cfae2ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Estimator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "model = lr.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86c6f577-75e7-4b2e-a409-9a15ca4ea46c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© es un Transformer?\n",
    "\n",
    "Un Transformer es un objeto que aplica una transformaci√≥n sobre un dataset, sin aprender nada nuevo. Su funci√≥n principal es:\n",
    "\n",
    "Aplicar .transform() para crear un nuevo DataFrame.\n",
    "\n",
    "üí° Ejemplo: model producido por LogisticRegression.fit(), o PipelineModel, o StandardScalerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "743d41f5-19f4-4d44-886a-ebe50d1b4e97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Transformer\n",
    "transformed = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4925e41a-790b-49ac-9339-9e8abdbfa157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## En el contexto de un Pipeline\n",
    "\n",
    "Un Pipeline est√° compuesto de etapas (stages) que pueden ser:\n",
    "\n",
    "Estimators ‚Üí deben ser ajustados (fit)\n",
    "\n",
    "Transformers ‚Üí aplican transformaciones (transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93938429-9cc6-4cdd-b246-0bf2963c7c2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, StandardScalerModel, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Sup√≥n que ya tienes un StandardScalerModel entrenado previamente\n",
    "scaler_model = StandardScalerModel.load(\"path/to/scaler_model\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=\"category\", outputCol=\"category_indexed\"),  # Estimator\n",
    "    scaler_model,                                                      # Transformer\n",
    "    LogisticRegression(featuresCol=\"features\", labelCol=\"label\")       # Estimator\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f765b5a-4f02-4fb0-a835-75a001a728f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "**Estimators que aparecen en el examen**\n",
    "\n",
    "| Estimator                | Tipo                         | Contexto en el examen                                                        |\n",
    "| ------------------------ | ---------------------------- | ---------------------------------------------------------------------------- |\n",
    "| `StringIndexer`          | Preprocesamiento             | Transformar texto a √≠ndice num√©rico antes de entrenar                        |\n",
    "| `OneHotEncoder`          | Preprocesamiento             | Cuando el √≠ndice generado se usa como feature                                |\n",
    "| `StandardScaler`         | Preprocesamiento             | Preguntas con variables num√©ricas que deben escalarse                        |\n",
    "| `PCA`                    | Reducci√≥n de dimensionalidad | Escenario con muchas variables correlacionadas                               |\n",
    "| `VectorAssembler`        | Feature engineering          | Se usa en la mayor√≠a de pipelines (reconocible por `inputCols`, `outputCol`) |\n",
    "| `LogisticRegression`     | Modelo de clasificaci√≥n      | Com√∫n en preguntas sobre interpretabilidad o rendimiento                     |\n",
    "| `LinearRegression`       | Modelo de regresi√≥n          | Aparece menos, pero presente en problemas num√©ricos                          |\n",
    "| `DecisionTreeClassifier` | Modelo de clasificaci√≥n      | Opci√≥n en preguntas de comparaci√≥n de modelos                                |\n",
    "| `RandomForestClassifier` | Modelo de clasificaci√≥n      | Aparece como alternativa en comparaci√≥n vs GBT                               |\n",
    "| `GBTClassifier`          | Modelo de clasificaci√≥n      | Muy com√∫n en preguntas sobre overfitting y evaluaci√≥n                        |\n",
    "| `GBTRegressor`           | Modelo de regresi√≥n          | Menos frecuente, pero presente en pipelines de regresi√≥n                     |\n",
    "\n",
    "\n",
    "**Transformers que aparecen en el examen**\n",
    "\n",
    "| Transformer               | Proviene de...                   | Contexto en el examen                                |\n",
    "| ------------------------- | -------------------------------- | ---------------------------------------------------- |\n",
    "| `StringIndexerModel`      | `.fit()` de `StringIndexer`      | Usado para aplicar transformaciones ya ajustadas     |\n",
    "| `OneHotEncoderModel`      | `.fit()` de `OneHotEncoder`      | Cuando se pregunta por el resultado del pipeline     |\n",
    "| `StandardScalerModel`     | `.fit()` de `StandardScaler`     | Escenario donde se aplica escalado antes de entrenar |\n",
    "| `PCAModel`                | `.fit()` de `PCA`                | Cuando hay reducci√≥n de features antes del modelo    |\n",
    "| `LogisticRegressionModel` | `.fit()` de `LogisticRegression` | Predicci√≥n, evaluaci√≥n, m√©tricas                     |\n",
    "| `GBTClassificationModel`  | `.fit()` de `GBTClassifier`      | Aparece en preguntas de evaluaci√≥n de performance    |\n",
    "| `PipelineModel`           | `.fit()` de un `Pipeline`        | Muy com√∫n en preguntas con c√≥digo de varios pasos    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c226a035-5bb8-4da6-aad7-207dd8db81d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Develop a training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f63bffc-9c57-42a9-92d4-a0893e86a667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© es un pipeline de entrenamiento?\n",
    "Un pipeline de entrenamiento es una estructura modular que encapsula todo el flujo de machine learning:\n",
    "\n",
    "- Preparaci√≥n de datos\n",
    "- Transformaciones\n",
    "- Entrenamiento del modelo\n",
    "- (Opcional) Validaci√≥n\n",
    "- (Opcional) Evaluaci√≥n y persistencia\n",
    "\n",
    "En PySpark, se representa con el objeto Pipeline de pyspark.ml."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "298758da-1b71-4300-bb75-59090d2b3144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© componentes se usan en Spark ML Pipelines?\n",
    "1. Transformers\n",
    "Objetos que aplican .transform(df)\n",
    "\n",
    "No requieren aprendizaje\n",
    "\n",
    "Ejemplos: VectorAssembler, MinMaxScalerModel, StandardScalerModel, PCAModel\n",
    "\n",
    "2. Estimators\n",
    "Objetos que requieren .fit(df) para aprender de los datos\n",
    "\n",
    "Devuelven Transformers\n",
    "\n",
    "Ejemplos: StringIndexer, LogisticRegression, GBTClassifier, RandomForestRegressor\n",
    "\n",
    "3. Pipeline\n",
    "Contenedor de etapas ordenadas (stages = [])\n",
    "\n",
    "Combina estimadores y transformers\n",
    "\n",
    ".fit(df) entrena todo el pipeline, devuelve un PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53a3b0f2-8053-4e9b-af68-82d8ea39ba6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=\"category\", outputCol=\"category_indexed\"),  # Estimator\n",
    "    VectorAssembler(\n",
    "        inputCols=[\"feature1\", \"feature2\", \"category_indexed\"],\n",
    "        outputCol=\"features\"\n",
    "    ),  # Transformer\n",
    "    LogisticRegression(featuresCol=\"features\", labelCol=\"label\")  # Estimator\n",
    "])\n",
    "\n",
    "# Entrenamiento completo del pipeline\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# Aplicaci√≥n a datos de test\n",
    "predictions = pipeline_model.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "659b6341-c26e-4140-ac11-81ba081c10cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "| Elemento                  | Clave para examen                        |\n",
    "| ------------------------- | ---------------------------------------- |\n",
    "| Objetivo del pipeline     | Organizar pasos ML de forma reproducible |\n",
    "| Composici√≥n               | Estimators + Transformers                |\n",
    "| Ejecuci√≥n                 | `pipeline.fit()` produce `PipelineModel` |\n",
    "| Aplicaci√≥n a nuevos datos | `pipeline_model.transform()`             |\n",
    "| Uso en tuning             | Compatible con CV y hyperopt             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be97cc77-5009-411d-af40-352f91447747",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Use Hyperopt's fmin operation to tune a model's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c03086b2-8b3f-4593-aec9-c34a371f5c65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© es Hyperopt?\n",
    "Hyperopt es una librer√≠a de optimizaci√≥n de hiperpar√°metros basada en b√∫squeda Bayesiana. Es m√°s eficiente que grid o random search para espacios de b√∫squeda grandes.\n",
    "\n",
    "Databricks lo integra con su framework de ML para escalar f√°cilmente los experimentos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cd46490-a385-486a-8037-72967ea1a39a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sintaxis general de fmin\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective_function,         # Funci√≥n objetivo (devuelve la m√©trica a minimizar)\n",
    "    space=search_space,            # Espacio de b√∫squeda de hiperpar√°metros\n",
    "    algo=tpe.suggest,              # Algoritmo de b√∫squeda (TPE = Tree-structured Parzen Estimator)\n",
    "    max_evals=50,                  # N√∫mero m√°ximo de evaluaciones\n",
    "    trials=Trials()                # Objeto opcional para guardar resultados\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5249a20-32f2-4bfe-885a-e4ff5b3a038e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Elemento    | Descripci√≥n                                                          | Tipo en examen                         |\n",
    "| ----------- | -------------------------------------------------------------------- | -------------------------------------- |\n",
    "| `fn`        | Funci√≥n que entrena el modelo y devuelve una m√©trica (ej: `loss`)    | Preguntan qu√© retorna, qu√© espera      |\n",
    "| `space`     | Diccionario o estructura que define los hiperpar√°metros y sus rangos | Te preguntan c√≥mo definirlo            |\n",
    "| `algo`      | Algoritmo de b√∫squeda (usualmente `tpe.suggest`)                     | Preguntan cu√°l es el m√°s eficiente     |\n",
    "| `max_evals` | Cu√°ntas combinaciones probar                                         | Preguntas de costo computacional       |\n",
    "| `Trials()`  | Objeto para registrar los experimentos                               | Preguntan si es obligatorio (no lo es) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff07c04d-5e6d-43f5-bab5-12c421233299",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def objective(params):\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_val)\n",
    "    loss = log_loss(y_val, preds)\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [50, 100, 150]),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt']),\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=Trials()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ecc2008-a912-4d81-a41e-a7ac7cddfd12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "**NOTEBOOK CON EJEMPLO**\n",
    "https://docs.databricks.com/aws/en/machine-learning/automl-hyperparam-tuning/hyperopt-distributed-ml\n",
    "\n",
    "| Concepto         | Detalles                                                                    |\n",
    "| ---------------- | --------------------------------------------------------------------------- |\n",
    "| `hp.choice`      | Selecci√≥n discreta entre valores                                            |\n",
    "| `hp.uniform`     | N√∫meros continuos entre dos valores                                         |\n",
    "| `hp.quniform`    | N√∫meros enteros escalonados (`start`, `end`, `step`)                        |\n",
    "| Funci√≥n objetivo | Debe retornar un diccionario con `loss` y `status`                          |\n",
    "| M√©trica objetivo | `loss` debe ser **m√≠nima**, t√≠picamente `log_loss`, `RMSE`, etc             |\n",
    "| `fmin`           | Encuentra la mejor combinaci√≥n de hiperpar√°metros seg√∫n la funci√≥n objetivo |\n",
    "\n",
    "‚ö†Ô∏è Cuando uses Hyperopt con MLlib y otros algoritmos de entrenamiento distribuido, no pases el argumento **trials** a fmin(). Si no incluyes el argumento trials, Hyperopt usar√° la clase Trials por defecto, que se ejecuta en el driver del cl√∫ster. Hyperopt necesita evaluar cada prueba (trial) en el nodo driver para que cada prueba pueda iniciar trabajos de entrenamiento distribuidos.\n",
    "\n",
    "No uses la clase SparkTrials con MLlib. SparkTrials est√° dise√±ada para distribuir pruebas en algoritmos que no son distribuidos por s√≠ mismos. MLlib ya utiliza computaci√≥n distribuida y no es compatible con SparkTrials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd85f29d-6bf3-4e07-84f1-fd2623ca22d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Perform random or grid search or Bayesian search as a method for tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cd12851-6252-412f-8493-2b787cf8426e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Grid Search (B√∫squeda por rejilla)\n",
    "\n",
    "Eval√∫a todas las combinaciones posibles de un conjunto definido de valores.\n",
    "\n",
    "{\n",
    "  \"maxDepth\": [5, 10],\n",
    "  \"minInstancesPerNode\": [1, 5]\n",
    "}\n",
    "\n",
    "Genera 4 combinaciones:\n",
    "\n",
    "- (5,1)\n",
    "- (5,5)\n",
    "- (10,1)\n",
    "- (10,5)\n",
    "\n",
    "**Ventajas:**\n",
    "- Exhaustivo ‚Üí encuentra el mejor dentro de los valores que definiste.\n",
    "- F√°cil de entender.\n",
    "\n",
    "**Desventajas:**\n",
    "- Costoso: crece exponencialmente con el n√∫mero de par√°metros y valores.\n",
    "- No generaliza fuera de los valores definidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e26db059-f3ec-43a8-9825-cb890c00766e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bayesian Search (ej. TPE con Hyperopt)\n",
    "Usa los resultados anteriores para predecir qu√© combinaciones valdr√°n la pena probar.\n",
    "\n",
    "- Construye un modelo probabil√≠stico del espacio de b√∫squeda.\n",
    "- Escoge el pr√≥ximo punto bas√°ndose en cu√°l tiene m√°s probabilidad de ser mejor (balancea exploraci√≥n y explotaci√≥n).\n",
    "\n",
    "\n",
    "**Ventajas:**\n",
    "\n",
    "Aprende con cada evaluaci√≥n ‚Üí mejora progresiva.\n",
    "M√°s eficiente que Random/Grid en espacios complejos.\n",
    "Especialmente √∫til cuando hay tiempo/costo limitado.\n",
    "\n",
    "**Desventajas:**\n",
    "\n",
    "M√°s dif√≠cil de entender e implementar.\n",
    "Menos reproducible (dependiente del orden de evaluaciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8695e1d0-010a-4b18-9fee-47b374774015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c60c706-be8e-417f-9452-359a407e8224",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4eca84d-854e-4345-9f15-0c5eb6c81b30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| M√©todo         | Inteligente | Evaluaciones | Exploraci√≥n | Velocidad  | Costoso  |\n",
    "| -------------- | ----------- | ------------ | ----------- | ---------- | -------- |\n",
    "| Grid Search    | ‚ùå           | Todas        | Baja        | Lento      | S√≠       |\n",
    "| Random Search  | ‚ùå           | Aleatorias   | Alta        | R√°pido     | Moderado |\n",
    "| Bayesian (TPE) | ‚úÖ           | Dirigidas    | Media       | Muy r√°pido | No       |\n",
    "\n",
    "**¬øQu√© debes saber para el examen?**\n",
    "\n",
    "- Grid Search ‚Üí exhaustivo, costoso, √∫til si espacio reducido.\n",
    "- Random Search ‚Üí m√°s eficiente, √∫til si espacio es amplio.\n",
    "- Bayesian Search (TPE) ‚Üí aprende con cada intento, recomendado en escenarios de recursos limitados.\n",
    "- En Databricks, Hyperopt implementa Bayesian Search por defecto con tpe.suggest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12612f96-8735-429a-8ca7-2d00a3ea1e03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parallelize single node models for hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e248aa7-f97c-41f5-9723-119a4aaa3d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**¬øQu√© significa ‚Äúparalelizar modelos single-node‚Äù?**\n",
    "En el contexto de tuning de hiperpar√°metros, especialmente con m√©todos como Hyperopt, es frecuente ejecutar muchos experimentos independientes. Cada combinaci√≥n de hiperpar√°metros genera un nuevo modelo que debe ser:\n",
    "\n",
    "- Entrenado (fit),\n",
    "- Validado (evaluate),\n",
    "- Comparado con otros.\n",
    "\n",
    "üîÅ Estos entrenamientos son independientes unos de otros ‚Üí se pueden correr en paralelo.\n",
    "\n",
    "**¬øQu√© es un ‚Äúsingle-node model‚Äù?**\n",
    "Son modelos entrenados en una sola m√°quina (no distribuidos), por ejemplo:\n",
    "\n",
    "- RandomForestClassifier de sklearn o pyspark.ml\n",
    "- LogisticRegression\n",
    "- XGBoost en modo local\n",
    "\n",
    "Aunque estos modelos no escalan naturalmente a m√∫ltiples nodos, el tuning s√≠ puede distribuirse, porque los experimentos no dependen entre s√≠.\n",
    "\n",
    "**¬øC√≥mo se paraleliza en Databricks con Hyperopt?**\n",
    "Databricks soporta el modo paralelo de Hyperopt usando spark_trials, una utilidad que permite distribuir los experimentos en un cl√∫ster Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "124ed1f0-be70-4b07-8280-ed0d9990239c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, SparkTrials\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir funci√≥n objetivo\n",
    "def objective(params):\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, preds)\n",
    "    return {'loss': -f1, 'status': STATUS_OK}\n",
    "\n",
    "# Definir espacio de b√∫squeda\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', [5, 10, 15]),\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 10)\n",
    "}\n",
    "\n",
    "# Paralelizar con SparkTrials\n",
    "spark_trials = SparkTrials(parallelism=4)\n",
    "\n",
    "best_model = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=spark_trials  # <-- distribuci√≥n en cl√∫ster\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb266e62-f0d9-4936-970a-f6978d899173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "| Par√°metro   | `Trials` (default) | `SparkTrials`           |\n",
    "| ----------- | ------------------ | ----------------------- |\n",
    "| Paralelismo | ‚ùå No               | ‚úÖ S√≠                    |\n",
    "| Entorno     | Local (1 nodo)     | Cl√∫ster Databricks      |\n",
    "| Ideal para  | Debug, tests       | Producci√≥n, tuning real |\n",
    "\n",
    "Puedes controlar el n√∫mero de evaluaciones simult√°neas con parallelism=n.\n",
    "\n",
    "**Lo que puede aparecer en el examen:**\n",
    "- Saber que SparkTrials se usa para paralelizar tuning.\n",
    "- Identificar cu√°ndo vale la pena paralelizar (muchas combinaciones, modelos costosos).\n",
    "- Entender que los modelos se entrenan en paralelo, no dentro del mismo modelo, sino a nivel de tuning.\n",
    "- Reconocer que esto se puede aplicar a modelos que no son distribuidos (como sklearn, xgboost, pyspark.ml).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25c797e1-5c0a-440c-b022-16830b2fa786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Describe the benefits and downsides of using cross-validation over a train-validation split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "add7059b-0409-4ada-adab-454150c5a323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ¬øQu√© es Train-Validation Split?\n",
    "Es la forma m√°s sencilla de evaluar un modelo:\n",
    "\n",
    "Se parte el dataset en dos subconjuntos:\n",
    "\n",
    "- Train set (por ejemplo, 80%)\n",
    "- Validation set (por ejemplo, 20%)\n",
    "\n",
    "Se entrena el modelo en el train set y se eval√∫a en el validation set.\n",
    "\n",
    "| Ventaja                     | Explicaci√≥n                                                                                |\n",
    "| --------------------------- | ------------------------------------------------------------------------------------------ |\n",
    "| ‚úÖ R√°pido                    | Solo se entrena una vez. Ideal para grandes vol√∫menes de datos o cuando el tiempo importa. |\n",
    "| ‚úÖ F√°cil de implementar      | No necesitas bucles, simplemente haces `.randomSplit()` en Spark.                          |\n",
    "| ‚úÖ Menor carga computacional | √ötil si est√°s haciendo tuning con muchos modelos.                                          |\n",
    "\n",
    "| Desventaja                                   | Explicaci√≥n                                                                                         |\n",
    "| -------------------------------------------- | --------------------------------------------------------------------------------------------------- |\n",
    "| ‚ùå Alta varianza                              | La performance depende **mucho de c√≥mo cay√≥ el 20%** del validation set. Podr√≠as tener mala suerte. |\n",
    "| ‚ùå No aprovecha todos los datos para entrenar | Solo el 80% se usa para entrenar.                                                                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d00d0a8-e987-469a-96cf-646cf72131b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## ¬øQu√© es Cross-Validation (CV)?\n",
    "Es un enfoque m√°s robusto:\n",
    "\n",
    "- El dataset se divide en k partes (folds), por ejemplo, 5.\n",
    "- Se entrena y valida el modelo k veces, rotando los folds.\n",
    "\n",
    "Se calcula el promedio del rendimiento.\n",
    "\n",
    "| Ventaja                           | Explicaci√≥n                                                            |\n",
    "| --------------------------------- | ---------------------------------------------------------------------- |\n",
    "| ‚úÖ M√°s robusto                     | Reduce la varianza. La evaluaci√≥n es m√°s confiable.                    |\n",
    "| ‚úÖ Usa todos los datos             | Cada observaci√≥n act√∫a como parte del validation set en alg√∫n momento. |\n",
    "| ‚úÖ M√°s justo para comparar modelos | √ötil en selecci√≥n de hiperpar√°metros y algoritmos.                     |\n",
    "\n",
    "| Desventaja     | Explicaci√≥n                                                   |\n",
    "| -------------- | ------------------------------------------------------------- |\n",
    "| ‚ùå M√°s lento    | Se entrena el modelo k veces. Si k=5, es 5 veces m√°s trabajo. |\n",
    "| ‚ùå M√°s complejo | Especialmente si haces Grid Search o pipelines distribuidos.  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da8676f9-fe74-4dff-a718-c68a282b52ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "| Escenario                               | ¬øQu√© usar?                            | Justificaci√≥n                                    |\n",
    "| --------------------------------------- | ------------------------------------- | ------------------------------------------------ |\n",
    "| Dataset muy grande (millones de filas)  | Train-validation split                | M√°s r√°pido, el volumen ya garantiza diversidad.  |\n",
    "| Dataset peque√±o o desequilibrado        | Cross-validation                      | Asegura una evaluaci√≥n robusta y balanceada.     |\n",
    "| Tuning intensivo (Grid o Random Search) | Train-validation split con test final | Reduce el costo computacional.                   |\n",
    "| Validaci√≥n final para comparar modelos  | Cross-validation                      | Da confianza estad√≠stica al comparar resultados. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b0eb1ab-5bc5-48bb-a9dd-a5d2bc7e8acc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Use common classification metrics: F1, Log Loss, ROC/AUC, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b68110cf-693b-4d2b-a680-0b169d131add",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Metricas mencionadas en la academia:\n",
    "\n",
    "Para modelos supervisados: Accuracy, precision , recall, F1 Score, Log loss (Cross-Entropy Loss), ROC/AUC (√Årea bajo la curva ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d742449b-fb81-440a-97e9-0cbfa7bdca83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## F1 Score\n",
    "\n",
    "**Qu√© mide:** La media arm√≥nica entre precisi√≥n (precision) y exhaustividad (recall).\n",
    "\n",
    "**Formula**\n",
    "\n",
    "F1= 2‚ãÖ(Precision‚ãÖRecall)/ Precision+Recall\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando tienes clases desbalanceadas (por ejemplo, fraude, enfermedad rara).\n",
    "- Cuando falsos positivos y falsos negativos son importantes.\n",
    "- Mejor que accuracy si los datos est√°n desbalanceados.\n",
    "\n",
    "**Recuerda:**\n",
    "F1 alto = buen balance entre precision y recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "630f4d09-ca45-47a1-b621-7bb2561dcf04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log Loss (a.k.a. Logarithmic Loss, Cross-Entropy Loss)\n",
    "**Qu√© mide:** \n",
    "- Cu√°nto se equivoca el modelo al predecir probabilidades.\n",
    "- Penaliza mucho las predicciones seguras pero err√≥neas.\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando necesitas evaluar la calidad de las probabilidades predichas, no solo etiquetas.\n",
    "- Es la m√©trica por defecto en muchos clasificadores probabil√≠sticos.\n",
    "- √ötil en escenarios donde la calibraci√≥n de probabilidad es cr√≠tica (ej. predicci√≥n m√©dica, scoring financiero).\n",
    "\n",
    "**Recuerda:**\n",
    "- Menor LogLoss = mejor modelo.\n",
    "- Puede ser bajo aunque el modelo se equivoque poco, si las probabilidades son poco confiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71c22750-9a4f-49f6-bc37-5633fc81a414",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ROC-AUC (Receiver Operating Characteristic - Area Under Curve)**\n",
    "\n",
    "**Qu√© mide:**\n",
    "- La capacidad del modelo para separar clases positivas y negativas en m√∫ltiples umbrales.\n",
    "- Compara tasa de verdaderos positivos (TPR) vs tasa de falsos positivos (FPR) a distintos umbrales.\n",
    "\n",
    "**√Årea bajo la curva = ROC-AUC.**\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Evaluaci√≥n general de la capacidad discriminatoria del modelo.\n",
    "- Muy √∫til en datasets desbalanceados.\n",
    "- Cuando el umbral de decisi√≥n puede cambiar seg√∫n el caso de uso.\n",
    "\n",
    "**Recuerda:**\n",
    "- AUC = 0.5 ‚Üí modelo aleatorio.\n",
    "- AUC = 1.0 ‚Üí modelo perfecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca4a0196-53f0-457f-ad4a-10c83d4906f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Accuracy\n",
    "\n",
    "**Qu√© mide:**\n",
    "Proporci√≥n de predicciones correctas sobre el total.\n",
    "\n",
    "**Ventaja**: Muy f√°cil de entender.\n",
    "\n",
    "**Desventaja:**\n",
    "\n",
    "Enga√±osa con datos desbalanceados.\n",
    "Por ejemplo, si el 95% de los casos son clase 0, un modelo que siempre predice 0 tendr√° 95% de accuracy‚Ä¶ aunque no haga nada √∫til.\n",
    "\n",
    "Uso recomendado:\n",
    "Solo cuando las clases est√°n balanceadas y los errores en ambas clases tienen el mismo costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9574d11-374c-4258-b258-577da00ac383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Precision (Precisi√≥n o Valor Predictivo Positivo)**\n",
    "\n",
    "**Qu√© mide:**\n",
    "- La proporci√≥n de predicciones positivas que son realmente correctas.\n",
    "- De todas las veces que el modelo predijo la clase positiva, cu√°ntas veces acert√≥.\n",
    "\n",
    "**F√≥rmula:**  \n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando es m√°s importante **evitar falsos positivos**.\n",
    "- En contextos donde etiquetar algo como positivo tiene un **costo alto si se comete un error** (por ejemplo, spam, detecci√≥n de tumores falsos, sistemas judiciales).\n",
    "- Cuando necesitas que las predicciones positivas sean confiables.\n",
    "\n",
    "**Recuerda:**\n",
    "- Precision = 1.0 ‚Üí el modelo no comete ning√∫n falso positivo.\n",
    "- Precision = 0.0 ‚Üí todas las predicciones positivas fueron incorrectas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37f86709-e0c2-4073-976b-87e7ac546793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Recall (Sensibilidad o Tasa de Verdaderos Positivos)\n",
    "\n",
    "**Qu√© mide:**\n",
    "- La proporci√≥n de verdaderos positivos (TP) que el modelo logra identificar correctamente.\n",
    "- De todas las observaciones que realmente pertenecen a la clase positiva, cu√°ntas fueron correctamente detectadas.\n",
    "\n",
    "**F√≥rmula:**  \n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando es m√°s importante **capturar todos los casos positivos**.\n",
    "- En problemas donde los falsos negativos tienen un **alto costo** (por ejemplo, detecci√≥n de enfermedades, fraudes, fallos de seguridad).\n",
    "- Cuando prefieres minimizar el riesgo de pasar por alto un positivo.\n",
    "\n",
    "**Recuerda:**\n",
    "- Recall = 1.0 ‚Üí el modelo no comete ning√∫n falso negativo.\n",
    "- Recall = 0.0 ‚Üí el modelo no detecta ning√∫n positivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46838bee-5800-42ba-8cfc-c7380c3aab22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "| M√©trica              | √ötil cuando‚Ä¶                      | Detalles clave                                                             |\n",
    "| -------------------- | --------------------------------- | -------------------------------------------------------------------------- |\n",
    "| **Accuracy**         | Las clases est√°n balanceadas      | $(TP + TN) / total$. No recomendable si hay desbalance.                    |\n",
    "| **Precision**        | Costo de falsos positivos es alto | $\\frac{TP}{TP + FP}$. ¬øQu√© tan confiables son los positivos predichos?     |\n",
    "| **Recall**           | Costo de falsos negativos es alto | $\\frac{TP}{TP + FN}$. ¬øCu√°ntos positivos reales detecta el modelo?         |\n",
    "| **PR-AUC**           | Clases muy desbalanceadas         | AUC de la curva Precision-Recall. M√°s informativa que ROC-AUC en ese caso. |\n",
    "| **Confusion Matrix** | Interpretabilidad                 | Te muestra TP, FP, FN, TN. Muy √∫til para analizar errores concretos.       |\n",
    "\n",
    "\n",
    "| M√©trica              | Rango | Valor √≥ptimo | Cu√°ndo usarla o interpretarla                                                                            |\n",
    "| -------------------- | ----- | ------------ | -------------------------------------------------------------------------------------------------------- |\n",
    "| **Accuracy**         | 0 a 1 | Cerca de 1   | Proporci√≥n de predicciones correctas. ‚ö†Ô∏è **Enga√±osa si los datos est√°n desbalanceados.**                 |\n",
    "| **Precision**        | 0 a 1 | Cerca de 1   | De los predichos positivos, cu√°ntos eran realmente positivos. ‚ö†Ô∏è Alta si pocos **falsos positivos**.     |\n",
    "| **Recall**           | 0 a 1 | Cerca de 1   | De los positivos reales, cu√°ntos fueron capturados. ‚ö†Ô∏è Alta si pocos **falsos negativos**.               |\n",
    "| **F1 Score**         | 0 a 1 | Cerca de 1   | Promedio arm√≥nico entre precision y recall. Ideal cuando hay desbalance o quieres compensar ambos.       |\n",
    "| **Log Loss**         | 0 a ‚àû | Cero (0)     | Penaliza probabilidades incorrectas. **M√°s bajo es mejor**. Afectado si predices mal con alta confianza. |\n",
    "| **ROC AUC**          | 0 a 1 | Cerca de 1   | Mide qu√© tan bien el modelo separa clases. Bueno con clases balanceadas. 0.5 = random.                   |\n",
    "| **PR AUC**           | 0 a 1 | Cerca de 1   | M√°s √∫til que ROC-AUC con **clases desbalanceadas**. Se enfoca en la clase positiva.                      |\n",
    "| **Confusion Matrix** | -     | -            | Muestra TP, FP, FN, TN. √ötil para calcular otras m√©tricas y entender errores.                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67fc9881-4e92-4ddb-a8d2-8a5eb94f3df8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Use common regression metrics: RMSE, MAE, R-squared, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86224311-7acf-4a79-8615-e19c5f4a705b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Metricas mencionadas en curso de la academia: R¬≤ (Coeficiente de determinaci√≥n),  Mean Absolute Error (MAE),  Mean Squared Error (MSE), Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3a953f7-d4ad-4441-bfdb-9b369584dbcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## R¬≤ (Coeficiente de determinaci√≥n)\n",
    "\n",
    "\n",
    "**Qu√© mide:**\n",
    "- Cu√°nta proporci√≥n de la varianza de la variable objetivo es explicada por el modelo.\n",
    "- Indica la calidad del ajuste del modelo a los datos.\n",
    "\n",
    "**F√≥rmula:**  \n",
    "R¬≤ = 1 - (Suma de errores del modelo / Suma de errores del modelo base)\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando quieres saber **qu√© tan bien explica el modelo la variabilidad de los datos**.\n",
    "- En modelos de regresi√≥n donde el objetivo es predecir valores continuos.\n",
    "\n",
    "**Recuerda:**\n",
    "- R¬≤ = 1.0 ‚Üí ajuste perfecto.\n",
    "- R¬≤ = 0.0 ‚Üí el modelo no mejora sobre una predicci√≥n constante (media).\n",
    "- R¬≤ < 0.0 ‚Üí el modelo es peor que simplemente predecir la media.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ebb72e1-5562-45db-a0aa-a289a9a1fe5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Mean Absolute Error (MAE)\n",
    "\n",
    "**Qu√© mide:**\n",
    "- El error promedio absoluto entre las predicciones y los valores reales.\n",
    "- Mide la magnitud promedio del error sin considerar su direcci√≥n.\n",
    "\n",
    "**F√≥rmula:**  \n",
    "MAE = (1/n) ‚àë |y_real - y_pred|\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando necesitas una m√©trica de error **f√°cil de interpretar en las mismas unidades de la variable objetivo**.\n",
    "- Cuando deseas que todos los errores cuenten por igual (sin penalizar m√°s los errores grandes).\n",
    "\n",
    "**Recuerda:**\n",
    "- MAE es m√°s robusta frente a valores at√≠picos que MSE o RMSE.\n",
    "- MAE = 0 ‚Üí el modelo predice perfectamente todos los valores.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eadebbf-0894-487e-96c6-93f85c34df4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Mean Squared Error (MSE)\n",
    "\n",
    "**Qu√© mide:**\n",
    "- El promedio de los errores al cuadrado entre las predicciones y los valores reales.\n",
    "- Penaliza los errores grandes de forma m√°s severa que MAE.\n",
    "\n",
    "**F√≥rmula:**  \n",
    "MSE = (1/n) ‚àë (y_real - y_pred)¬≤\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando quieres penalizar m√°s fuertemente los **errores grandes**.\n",
    "- En problemas donde los outliers son relevantes o deben evitarse.\n",
    "\n",
    "**Recuerda:**\n",
    "- MSE siempre es ‚â• 0.\n",
    "- Cuanto m√°s peque√±o, mejor es el modelo.\n",
    "- Est√° en unidades cuadradas de la variable objetivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ff68dd7-3ced-4d07-92d1-e46af9d72ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Root Mean Squared Error (RMSE)\n",
    "\n",
    "**Qu√© mide:**\n",
    "- La ra√≠z cuadrada del error cuadr√°tico medio.\n",
    "- Representa el error t√≠pico de predicci√≥n en las mismas unidades que la variable objetivo.\n",
    "\n",
    "**F√≥rmula:**  \n",
    "RMSE = ‚àö( (1/n) ‚àë (y_real - y_pred)¬≤ )\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Cuando quieres penalizar errores grandes y **mantener las unidades originales** de la variable.\n",
    "- Es √∫til para interpretar el error en el mismo contexto del negocio.\n",
    "\n",
    "**Recuerda:**\n",
    "- RMSE es m√°s sensible a errores grandes que MAE.\n",
    "- Cuanto menor sea el RMSE, mejor es el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83e782b5-f0f0-4f1b-b646-aa4e562ce65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "| M√©trica                                      | Rango   | Valor √≥ptimo | Qu√© mide                                                                                   | Cu√°ndo usarla o preferirla                                                                                                   |\n",
    "| -------------------------------------------- | ------- | ------------ | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **MAE** (Mean Absolute Error)                | 0 a ‚àû   | 0 (cero)     | Promedio de errores absolutos. Mide cu√°n lejos est√°n las predicciones del valor real.      | F√°cil de interpretar. Menos sensible a valores extremos (outliers).                                                          |\n",
    "| **RMSE** (Root Mean Squared Error)           | 0 a ‚àû   | 0 (cero)     | Ra√≠z cuadrada del promedio de los errores al cuadrado. Penaliza m√°s los errores grandes.   | √ötil si quieres castigar m√°s los errores grandes.                                                                            |\n",
    "| **R-squared** (Coeficiente de determinaci√≥n) | -‚àû a 1  | 1            | Cu√°nto del total de la varianza del target explica el modelo.                              | M√©trica est√°ndar general para evaluar qu√© tan bien se ajusta el modelo.                                                      |\n",
    "| **MAPE** (Mean Absolute Percentage Error)    | 0% a ‚àû% | 0%           | Error absoluto expresado como porcentaje del valor real.                                   | Bueno para presentaciones o comparaci√≥n entre modelos en escalas distintas. ‚ö†Ô∏è Puede fallar con valores reales cercanos a 0. |\n",
    "| **MSLE** (Mean Squared Logarithmic Error)    | 0 a ‚àû   | 0            | Similar a MSE, pero usa el log de los valores. Reduce impacto de errores en valores altos. | √ötil cuando te interesa el **error relativo**, no el valor absoluto.                                                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ac3e2b0-d859-406e-a7d4-c18ba0d6772e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Otras m√©tricas mencionadas en la academia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34dd7bc4-6af0-4479-b2d8-c15dfa938b78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Silhouette Score (√çndice de Silueta) - Modelos NO supervizados**\n",
    "\n",
    "**Qu√© mide:**\n",
    "- Qu√© tan bien se agrupa un punto dentro de su propio cl√∫ster en comparaci√≥n con otros cl√∫steres.\n",
    "- Eval√∫a **la cohesi√≥n y separaci√≥n** de los cl√∫steres.\n",
    "\n",
    "**F√≥rmula:**  \n",
    "Silhouette = (b - a) / max(a, b)  \n",
    "Donde:  \n",
    "- a = distancia media al resto de puntos en el mismo cl√∫ster  \n",
    "- b = distancia media al cl√∫ster m√°s cercano\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- Para **evaluar la calidad del clustering**, especialmente en k-means, DBSCAN, etc.\n",
    "- Para **comparar resultados con diferentes valores de k (n√∫mero de cl√∫steres)**.\n",
    "\n",
    "**Recuerda:**\n",
    "- Silhouette cerca de **1.0** ‚Üí puntos bien agrupados.\n",
    "- Silhouette cerca de **0.0** ‚Üí puntos en el borde entre cl√∫steres.\n",
    "- Silhouette **< 0.0** ‚Üí puntos mal asignados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75482217-f885-4b29-a0cf-f63fe57e16ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Elbow Method (M√©todo del Codo)**\n",
    "\n",
    "**Qu√© mide:**\n",
    "- Ayuda a determinar el n√∫mero √≥ptimo de cl√∫steres (**k**) al observar la variaci√≥n explicada por el modelo.\n",
    "\n",
    "**C√≥mo se aplica:**\n",
    "- Se entrena el modelo con diferentes valores de **k**.\n",
    "- Se grafica el valor de la inercia (Suma de errores cuadr√°ticos dentro del cl√∫ster: SSE) contra k.\n",
    "- El punto donde la **disminuci√≥n de SSE se vuelve menos pronunciada** es el ‚Äúcodo‚Äù, el valor √≥ptimo de k.\n",
    "\n",
    "**Cu√°ndo usarla:**\n",
    "- En algoritmos de clustering como **k-means**.\n",
    "- Para **estimar de forma visual y emp√≠rica el n√∫mero de cl√∫steres adecuados**.\n",
    "\n",
    "**Recuerda:**\n",
    "- No siempre hay un codo claro.\n",
    "- Es una **t√©cnica heur√≠stica**: se complementa bien con m√©tricas como Silhouette Score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "727f5c71-327a-481b-986b-e1145a9c6da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Choose the most appropriate metric for a given scenario objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "512b0506-b918-4849-82b2-7d4709f8fc50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clasificaci√≥n binaria (0 o 1)\n",
    "| Escenario                                                                         | M√©trica ideal          | ¬øPor qu√©?                                                               |\n",
    "| --------------------------------------------------------------------------------- | ---------------------- | ----------------------------------------------------------------------- |\n",
    "| **Clases balanceadas**, quieres precisi√≥n general                                 | **Accuracy**           | Sencilla y √∫til si el dataset est√° balanceado.                          |\n",
    "| **Clases desbalanceadas** (ej: 95% negativos)                                     | **F1 Score o ROC-AUC** | Accuracy es enga√±osa. F1 equilibra precisi√≥n y recall.                  |\n",
    "| **Evitar falsos negativos (FN)** es cr√≠tico (ej: fraude, c√°ncer)                  | **Recall**             | Detectar todos los positivos. Mejor un falso positivo que uno negativo. |\n",
    "| **Evitar falsos positivos (FP)** es m√°s cr√≠tico (ej: c√°rcel, alarmas falsas)      | **Precision**          | S√≥lo queremos marcar positivo si estamos muy seguros.                   |\n",
    "| Predices **probabilidades** y quieres medir qu√© tan bien calibrado est√° el modelo | **Log Loss**           | Penaliza fuertemente la sobreconfianza con errores.                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad874854-2938-42e3-80e4-b75ebf0dd019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clasificaci√≥n multiclase (m√°s de 2 clases)\n",
    "\n",
    "| Escenario                                                | M√©trica ideal                       | ¬øPor qu√©?                                   |\n",
    "| -------------------------------------------------------- | ----------------------------------- | ------------------------------------------- |\n",
    "| Todas las clases tienen similar importancia              | **Accuracy**                        | Correcto en general si no hay desbalance.   |\n",
    "| Algunas clases son m√°s importantes o hay desbalance      | **F1 macro o weighted**             | Equilibra la contribuci√≥n de cada clase.    |\n",
    "| Interesa m√°s una clase espec√≠fica (ej: detectar clase C) | **Precision/Recall para esa clase** | Foco en clase minoritaria o de alto riesgo. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "add9995f-d5e2-4a3d-812d-063c8e79487d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Regresi√≥n\n",
    "| Escenario                                                                              | M√©trica ideal                                    | ¬øPor qu√©?                                                                               |\n",
    "| -------------------------------------------------------------------------------------- | ------------------------------------------------ | --------------------------------------------------------------------------------------- |\n",
    "| Quieres un error promedio f√°cil de entender                                            | **MAE**                                          | Intuitivo. Poco sensible a outliers.                                                    |\n",
    "| Quieres penalizar errores grandes m√°s fuertemente                                      | **RMSE**                                         | Ideal si los errores grandes son muy costosos.                                          |\n",
    "| Quieres saber qu√© tan bien el modelo explica la varianza                               | **R-squared (R¬≤)**                               | Muy com√∫n. ‚ÄúQu√© tanto del target est√° explicado por el modelo‚Äù.                         |\n",
    "| Trabajas con **precios, ventas**, y necesitas comparar modelos entre escalas distintas | **MAPE**                                         | Da errores en porcentaje, muy √∫til para reporting. ‚ö†Ô∏è No usar si el target tiene ceros. |\n",
    "| Target fue **log-transformado (ej: np.log1p(y))**                                      | **Eval√∫a sobre np.expm1(pred)** y usa MAE o RMSE | Siempre deshace el log antes de evaluar. Evita m√©tricas sobre escala logar√≠tmica.       |\n",
    "| Quieres medir precisi√≥n relativa en crecimiento o tasas                                | **MSLE**                                         | Penaliza menos errores absolutos grandes; √∫til con datos de crecimiento.                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4865c862-f191-41cc-8229-c2d1951b979b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "| Concepto                                      | Pregunta frecuente                                                         |\n",
    "| --------------------------------------------- | -------------------------------------------------------------------------- |\n",
    "| ¬øAccuracy funciona con clases desbalanceadas? | ‚ùå No. Usa F1 o ROC-AUC.                                                    |\n",
    "| ¬øSe puede usar RMSE con log-transform?        | ‚úÖ Solo si deslog-transformas antes (`np.expm1`).                           |\n",
    "| ¬øMAPE falla con ceros?                        | ‚úÖ S√≠, porque divide por el valor real.                                     |\n",
    "| ¬øCu√°ndo usar Log Loss?                        | ‚úÖ Cuando predices probabilidades. Penaliza con fuerza los errores seguros. |\n",
    "| ¬øROC-AUC qu√© mide?                            | ‚úÖ La capacidad del modelo de rankear correctamente entre clases.           |\n",
    "\n",
    "**1. ¬øQu√© debes saber?**\n",
    "\n",
    "- Debes ser capaz de:\n",
    "- Distinguir entre m√©tricas de clasificaci√≥n y regresi√≥n.\n",
    "- Saber qu√© m√©trica favorece un objetivo espec√≠fico: minimizar falsos negativos, castigar errores grandes, interpretar probabilidades, etc.\n",
    "- Elegir m√©tricas cuando hay desbalance de clases, predicci√≥n de probabilidades, o necesidad de explicabilidad.\n",
    "- Identificar si el target fue log-transformado, y si se debe aplicar np.expm1() antes de evaluar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4dbea13-e14c-4698-af1b-0c70ae944dac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Identify the need to exponentiate log-transformed variables before calculating evaluation metrics or interpreting predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ece16505-0976-4a81-892a-8417fb34bc40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "¬øPor qu√© se usan transformaciones logar√≠tmicas en regresi√≥n?\n",
    "- Para que distribuciones muy sesgadas (skewed) se asemejen m√°s a una gaussiana (normal).\n",
    "- Para reducir el impacto de valores extremos o outliers.\n",
    "- Para que modelos lineales funcionen mejor cuando hay relaciones exponenciales o multiplicativas.\n",
    "\n",
    "¬øQu√© implica usar log en el target?\n",
    "Cuando transformas tu variable objetivo (y) con logaritmo antes de entrenar, est√°s haciendo que el modelo aprenda a predecir log(y), no y directamente.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14a7bc97-b908-4164-92ca-05b96255d11a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.withColumn(\"label\", log1p(\"price\"))  # log1p(x) = log(x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "616a6577-208e-4e84-8130-6b91aa2aac60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Entonces, ¬øqu√© error cometen muchos?**\n",
    "\n",
    "- Evaluar el modelo sobre log(y_pred) y log(y_test) est√° bien si te interesa performance en la escala logar√≠tmica.\n",
    "- Pero si quieres evaluar el rendimiento real (RMSE en d√≥lares, por ejemplo), tienes que invertir la transformaci√≥n (con expm1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ed7093c-5791-49ed-ba9d-4241c5417dee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expm1\n",
    "\n",
    "# Corrige predicciones antes de evaluar\n",
    "pred_df = pred_df.withColumn(\"prediction_exp\", expm1(\"prediction\"))\n",
    "pred_df = pred_df.withColumn(\"label_exp\", expm1(\"label\"))\n",
    "\n",
    "# Ahora s√≠ puedes calcular RMSE real\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label_exp\",\n",
    "    predictionCol=\"prediction_exp\",\n",
    "    metricName=\"rmse\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "218b7d21-6295-437b-8589-5056e68a42ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**¬øQu√© pasa si no haces expm1() antes de evaluar?**\n",
    "\n",
    "Tu RMSE, MAE o R¬≤ ser√° en la escala del log, y no representar√° errores reales en la escala del negocio.\n",
    "Por ejemplo:\n",
    "\n",
    "- Un error de 0.1 en log(price) no se traduce directamente en 0.1 d√≥lares.\n",
    "- Podr√≠as tener un modelo con bajo error logar√≠tmico, pero con errores enormes en precios reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b00db8a-7543-4c01-8524-3edd01e9102f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "| Situaci√≥n                                                      | ¬øAplico `expm1()` antes de evaluar? | M√©tricas que se afectan |\n",
    "| -------------------------------------------------------------- | ----------------------------------- | ----------------------- |\n",
    "| Quiero medir RMSE real en d√≥lares                              | ‚úÖ S√≠                                | RMSE, MAE, MAPE         |\n",
    "| Voy a interpretar predicciones (por ejemplo, precio estimado)  | ‚úÖ S√≠                                | Todas                   |\n",
    "| S√≥lo me interesa performance en log-escala (estudio acad√©mico) | ‚ùå No                                | RMSE (log), R¬≤ (log)    |\n",
    "| Estoy graficando residuos o errores                            | ‚úÖ S√≠                                | Para interpretar bien   |\n",
    "\n",
    "Pro tip (¬°s√∫per √∫til para el examen!):\n",
    "\n",
    "- Si ves \"label\" como log1p(y) en el c√≥digo, busca si usan expm1 antes de evaluar o graficar. Si no, probablemente hay un error que deber√°s identificar.\n",
    "- Te pueden mostrar dos pipelines, uno correcto y otro sin expm1() y preguntarte cu√°l da m√©tricas v√°lidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7afeab05-91ac-4f03-af6d-8d9a8e9a2089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assess the impact of model complexity and the bias variance tradeoff on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c119f69-2702-47d7-8ae2-ddf738783f4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**¬øQu√© es el tradeoff bias-variance?**\n",
    "\n",
    "Es un principio fundamental en machine learning que describe el equilibrio entre dos tipos de error que afectan al rendimiento del modelo:\n",
    "\n",
    "Tipo de error\tQu√© significa\tCausa principal\n",
    "Bias (sesgo)\tError por supuestos demasiado simples sobre los datos\tModelo demasiado simple (subajuste / underfitting)\n",
    "Varianza\tError por sensibilidad excesiva a los datos de entrenamiento\tModelo demasiado complejo (sobreajuste / overfitting)\n",
    "\n",
    "**Relaci√≥n con la complejidad del modelo**\n",
    "\n",
    "A medida que aumentas la complejidad del modelo:\n",
    "\n",
    "- El bias disminuye ‚Üí el modelo se ajusta mejor a los datos.\n",
    "- Pero la varianza aumenta ‚Üí el modelo se vuelve m√°s inestable frente a datos nuevos.\n",
    "\n",
    "Esto se conoce como la curva en U del error total:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20b973e2-c154-4628-8e7c-369065d104ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Puntos clave\n",
    "\n",
    "**Ejemplos en modelos reales**\n",
    "| Modelo o t√©cnica                   | Complejidad t√≠pica | Riesgo principal            |\n",
    "| ---------------------------------- | ------------------ | --------------------------- |\n",
    "| Regresi√≥n lineal                   | Baja               | Alto bias                   |\n",
    "| √Årbol de decisi√≥n con maxDepth=2   | Baja               | Alto bias                   |\n",
    "| √Årbol de decisi√≥n sin restricci√≥n  | Alta               | Alta varianza               |\n",
    "| Random Forest (con `n_estimators`) | Media              | Generaliza bien             |\n",
    "| Gradient Boosting                  | Alta               | Alta varianza si no regulas |\n",
    "| Regularizaci√≥n (L1/L2)             | Reduce complejidad | Baja varianza               |\n",
    "\n",
    "**Resumen que debes saber para el examen**\n",
    "\n",
    "| Concepto                        | Se√±ales t√≠picas                   | Soluciones                                                      |\n",
    "| ------------------------------- | --------------------------------- | --------------------------------------------------------------- |\n",
    "| **High bias (underfitting)**    | Error alto en train y test        | Aumentar complejidad, usar modelo m√°s flexible                  |\n",
    "| **High variance (overfitting)** | Error bajo en train, alto en test | Regularizaci√≥n, cross-validation, m√°s datos, simplificar modelo |\n",
    "| **Good generalization**         | Error similar en train y test     | ¬°Ideal!                                                         |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Section 3: Model Development",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
