{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93b7581f-9ac1-4c56-b44a-4d1f92e8f6a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Model Tracking with *MLflow*\n",
    "\n",
    "In this demo, we will explore the capabilities of MLflow, a comprehensive framework for the complete machine learning lifecycle. MLflow provides tools for tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\n",
    "\n",
    "In this demo, **we will focus on tracking and logging components of MLflow**. First, we will demonstrate how to track an experiment with MLflow and show various custom logging features including logging parameters, metrics, figures and arbitrary artifacts.\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "*By the end of this demo, you will be able to;*\n",
    "\n",
    "- Train a model using a Feature Store table as the modeling set.\n",
    "- Manually log parameters, metrics, models, and figures with MLflow tracking.\n",
    "- Log training dataset with model in MLflow\n",
    "- Log additional artifacts to a model run\n",
    "- Review an experiment using the MLflow UI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55de9470-ff84-4958-bca6-e778a6e8d6b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "- To run this notebook, you need to use one of the following Databricks runtime(s): **13.3.x-cpu-ml-scala2.12**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1982993f-0c6a-47a7-87d5-fad7ecf28c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "\n",
    "## MLflow with Unity Catalog\n",
    "\n",
    "Databricks has support for MLflow with Unity Catalog (UC) integration and workspace-based classic version. Although we won't go into the details of MLflow with UC in this demo, we will enable it. This means **models will be registered to UC**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db4b3e34-7a36-49b9-812c-07e9d96408fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade 'mlflow-skinny[databricks]'\n",
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5af5f908-9643-4e4b-9355-ce930d75369d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup script. This script will define configuration variables necessary for the demo. Execute the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f8463ba-7ca2-4939-87ec-23cc6f4a5e67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-01.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9e4a298-4e01-472a-b25c-839c892b46e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "\n",
    "### Other Conventions:\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc2d0b20-7f9f-48d7-8e73-d93d144643df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:           {DA.username}\")\n",
    "print(f\"Catalog Name:       {DA.catalog_name}\")\n",
    "print(f\"Schema Name:        {DA.schema_name}\")\n",
    "print(f\"Working Directory:  {DA.paths.working_dir}\")\n",
    "print(f\"User DB Location:   {DA.paths.datasets}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cf153bd-5407-40c7-be2b-f0c34ffdfcc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "\n",
    "## Prepare Dataset\n",
    "\n",
    "### Load Dataset\n",
    "\n",
    "In this section, we will leverage the Feature Store to load the dataset for our machine learning experiment. Instead of directly reading from a CSV file, we will use the Feature Store setup to create a feature table and then read the data from it. This approach enhances reproducibility and ensures consistency in the datasets used for training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6f09e2f-4139-42ab-a18c-232dd13759ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "feature_dataset = mlflow.data.load_delta(\n",
    "    table_name = f\"{DA.catalog_name}.{DA.schema_name}.diabetes_binary\",\n",
    "    name = \"diabetes_binary\"\n",
    ")\n",
    "\n",
    "feature_data_pd = feature_dataset.df.toPandas()\n",
    "\n",
    "# Drop the 'unique_id' column\n",
    "feature_data_pd = feature_data_pd.drop(\"unique_id\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a7941e3-f0ae-4c1b-8f60-a8b2f379dc5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(feature_data_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30c26b8e-a1cf-431f-ab2b-bbaab2198aba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert all columns in the DataFrame to the 'double' data type\n",
    "for column in feature_data_pd.columns:\n",
    "    feature_data_pd[column] = feature_data_pd[column].astype(\"double\")\n",
    "\n",
    "# If you want to see the updated types\n",
    "print(feature_data_pd.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db3ff607-f000-487d-ae7a-10c6706d130d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train / Test Split\n",
    "\n",
    "Before proceeding with model training, it's essential to split the dataset into training and testing sets. This step ensures that the model is trained on one subset of the data and evaluated on an independent subset, providing a reliable estimate of its performance on new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d054d1a-26dd-4c77-90ea-42b842fc2184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"We have {feature_data_pd.shape[0]} records in our source dataset\")\n",
    "\n",
    "# split target variable into its own dataset\n",
    "target_col = \"Diabetes_binary\"\n",
    "X_all = feature_data_pd.drop(labels=target_col, axis=1)\n",
    "y_all = feature_data_pd[target_col]\n",
    "\n",
    "# test / train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.95, random_state=42)\n",
    "print(f\"We have {X_train.shape[0]} records in our training dataset\")\n",
    "print(f\"We have {X_test.shape[0]} records in our test dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8489b6f4-2055-4434-b9a9-bf64becc7496",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fit and Log the Model\n",
    "\n",
    "Now that we have our training and testing sets, let's fit a Decision Tree model to the training data. During this process, we will use MLflow to log various aspects of the model, including parameters, metrics, and the resulting model itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcbef9c7-c0d6-4a81-b3ca-e38c0f204b8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dtc_params = {\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 50,\n",
    "    'min_samples_split': 20,\n",
    "    'min_samples_leaf': 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdc1cca4-bc81-4926-a3c3-1635e07a431e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this code, we use MLflow to start a run and log parameters such as the criterion and max_depth of the Decision Tree model. After fitting the model on the training data, we evaluate its performance on the test set and log the accuracy as a metric.\n",
    "\n",
    "⚠️ **Important:** MLflow autologging is **enabled by default on Databricks**. This means you don't need to do anything for supported libraries. In the next section, we are disabling it and manually log params, metrics etc. just to demonstrate how to do it manually when you need to log any custom model info.\n",
    "\n",
    "💡 **Note:** We won't define the `experiment` name, all `runs` generated in this notebook will be logged under the notebook title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40de8dbc-d9ff-43d5-9705-2c04eed3a21e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# register models in UC\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29632815-e917-4809-b5c6-8b7e977464c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Users/{DA.username}/Demo-1.2-Model-Tracking-with-MLflow\")\n",
    "\n",
    "# turn off autologging\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "model_name = f\"{DA.catalog_name}.{DA.schema_name}.diabetes-predictions\"\n",
    "\n",
    "# start an MLFlow run\n",
    "with mlflow.start_run(run_name=\"Model Tracking Demo\") as run:\n",
    "    \n",
    "    # log the dataset\n",
    "    mlflow.log_input(feature_dataset, context=\"source\")\n",
    "    mlflow.log_input(mlflow.data.from_pandas(X_train, source=feature_dataset.source), context=\"training\")\n",
    "    mlflow.log_input(mlflow.data.from_pandas(X_test, source=feature_dataset.source), context=\"test\")\n",
    "\n",
    "    # log our parameters\n",
    "    mlflow.log_params(dtc_params)\n",
    "    mlflow.log_param(\"param_name\", param_value)  # esta línea es un ejemplo, puedes omitirla o cambiarla\n",
    "\n",
    "    # fit our model\n",
    "    dtc = DecisionTreeClassifier(**dtc_params)\n",
    "    dtc_mdl = dtc.fit(X_train, y_train)\n",
    "\n",
    "    # define model signature\n",
    "    signature = infer_signature(X_all, y_all)\n",
    "\n",
    "    # log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=dtc_mdl,\n",
    "        artifact_path=\"model-artifacts\",\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "    # evaluate on the training set\n",
    "    y_pred = dtc_mdl.predict(X_train)\n",
    "    mlflow.log_metric(\"train_accuracy\", accuracy_score(y_train, y_pred))\n",
    "    mlflow.log_metric(\"train_precision\", precision_score(y_train, y_pred))\n",
    "    mlflow.log_metric(\"train_recall\", recall_score(y_train, y_pred))\n",
    "    mlflow.log_metric(\"train_f1\", f1_score(y_train, y_pred))\n",
    "\n",
    "    # evaluate on the test set\n",
    "    y_pred = dtc_mdl.predict(X_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"test_precision\", precision_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"test_recall\", recall_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"test_f1\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb011069-cc50-488e-9f8a-2194ee0537e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "can this point we can access all model details using run.info class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc6a737d-fd89-443f-9a40-b04c87c3ef4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42907d1f-a40c-46e6-a4f9-2caf9f3d3c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log Model Artifacts\n",
    "\n",
    "**In addition to logging parameters, metrics, and the model itself, we can also log artifacts—any files or data relevant to the run.**  \n",
    "Let’s set up an MLflow client to log artifacts after the run is completed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf7a1faa-4c02-4539-a1f5-074f504cd9cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.client import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3040cc5c-33db-4d88-883c-d1eb6a313ff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log Confusion Matrix\n",
    "\n",
    "The confusion matrix is a useful tool to visualize the classification performance of the model.  \n",
    "It provides insights into the true positive, true negative, false positive, and false negative predictions.\n",
    "\n",
    "Let's create the confusion matrix and **log it with MLflow** using `log_figure` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe773891-d0f5-4092-9862-8d309f502e77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Computing the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "# Creating a figure object and axes for the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plotting the confusion matrix using the created axes\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[1, 0])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "# Setting the title of the plot\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Now 'fig' can be used with MLflow's log_figure function\n",
    "client.log_figure(run.info.run_id, figure=fig, artifact_file=\"confusion_matrix.png\")\n",
    "\n",
    "# Showing the plot here for demonstration\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4deac05-b6d7-4785-8a57-4e99de6e9897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log Feature Importance\n",
    "\n",
    "Now, **let's examine and log the resulting model**.  \n",
    "We'll extract and plot the feature importances inferred from the Decision Tree model to understand which data features are most critical for successful prediction.\n",
    "\n",
    "Similar to the previous figure, we will use `log_figure` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1092ff41-2814-4fff-a441-eee7353a2680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retrieving feature importances\n",
    "feature_importances = dtc_mdl.feature_importances_\n",
    "feature_names = X_train.columns.to_list()\n",
    "\n",
    "# Plotting the feature importances\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_pos = np.arange(len(feature_names))\n",
    "ax.bar(y_pos, feature_importances, align='center', alpha=0.7)\n",
    "ax.set_xticks(y_pos)\n",
    "ax.set_xticklabels(feature_names, rotation=45)\n",
    "ax.set_ylabel('Importance')\n",
    "ax.set_title('Feature Importances in Decision Tree Classifier')\n",
    "\n",
    "# log to mlflow\n",
    "client.log_figure(run.info.run_id, figure=fig, artifact_file=\"feature_importances.png\")\n",
    "\n",
    "# display here\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48187c04-bb85-41d4-bb01-40b48d64dd7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log Tree Structure\n",
    "\n",
    "Decision trees make splitting decisions on different features at different critical values, and visualizing the tree structure helps us understand the decision logic. We'll plot the branching tree structure for better interpretation.\n",
    "\n",
    "We can get the tree in text format or as a graph. **To log the text format we will use `log_artifact` function.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bb3e413-7b9f-4320-9456-bcbb35dbd5cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The fitted DecisionTreeClassifier model has {dtc_mdl.tree_.node_count} nodes and is up to {dtc_mdl.tree_.max_depth} levels deep.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cac975e-c164-4d2f-82a3-0864db25e805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\"This is a very large decision tree, printing out the full tree logic, we can see it is vast and sprawling:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd20010-959b-4949-b3ea-875ee9649290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "# Exportar la estructura del árbol como texto\n",
    "text_representation = export_text(dtc_mdl, feature_names=feature_names)\n",
    "print(text_representation)\n",
    "\n",
    "# Guardar a un archivo local\n",
    "tree_struct_filename = \"tree_structure.txt\"\n",
    "with open(tree_struct_filename, 'w') as f:\n",
    "    f.write(text_representation)\n",
    "\n",
    "# Log a MLflow\n",
    "client.log_artifact(run.info.run_id, tree_struct_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6dcb693-dba1-4c1e-ad7b-dac986ff2b62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\"Let's create a visually better looking version of this tree and log it with MLflow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "245c89e2-2bcf-4c52-900d-b23dc8a33642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot de la estructura del árbol\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "plot_tree(\n",
    "    dtc_mdl,\n",
    "    feature_names=feature_names,\n",
    "    max_depth=2,\n",
    "    class_names=['0', '1'],\n",
    "    filled=True,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Decision Tree Structure')\n",
    "\n",
    "# Registrar con MLflow\n",
    "client.log_figure(run.info.run_id, fig, 'decision_tree_structure.png')\n",
    "\n",
    "# Mostrar en notebook\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54112fbd-c18c-44c9-a314-3d065e7b593a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Review the Model via the UI\n",
    "To review the model and its details, follow these step-by-step instructions:\n",
    "\n",
    "Step 1: Go to the \"Experiments\" Section:\n",
    "\n",
    "Click the Experiment icon 🧪 in the notebook’s right sidebar.\n",
    "\n",
    "In the Experiment Runs sidebar, click the 🔗 icon next to the date of the run.\n",
    "The MLflow Run page displays, showing details of the run, including parameters, metrics, tags, and a list of artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f5fb44c-fde0-4c4b-996d-be66ff6ac6d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe1de02-4ee4-481e-9610-7236e820f983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Locate Your Experiment:\n",
    "- Find the experiment name you specified in your MLflow run.\n",
    "\n",
    "### Step 3: Review Run Details:\n",
    "- Click on the experiment name to view the runs within that experiment.\n",
    "- Locate the specific run you want to review.\n",
    "\n",
    "### Step 4: Reviewing Artifacts and Metrics:\n",
    "- Click on the run to see detailed information.\n",
    "  - Navigate to the **\"Artifacts\"** tab to view logged artifacts.\n",
    "  - Navigate to the **\"Metrics\"** tab to view logged metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0800b8b-ec7c-4565-8afb-6a58750b9837",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07-M2-Demo3: Model Tracking with MLflow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
