{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "578d4f28-72e7-459f-8a69-cb885c167d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training Regression and Classification Models\n",
    "\n",
    "In this demo, we will guide you through essential concepts and practical applications of machine learning. The first demo will be related to fitting a regression model and the second demo will be related to classification models. In these demos, you will learn how to retrieve data and fit models using notebooks. In addition, you will learn how to interpret results using visualization tools and various model metrics.\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "**By the end of this demo, you will be able to;**\n",
    "\n",
    "- Fit a linear regression model on modeling data using the sklearn API.\n",
    "- Interpret a fit sklearn linear model’s coefficients and intercept.\n",
    "- Fit a decision tree model using sklearn API and training data.\n",
    "- Visualize a sklearn tree’s split points.\n",
    "- Identify which metrics are tracked by MLflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48ea2889-9324-4092-8b30-ea5603af3758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "- To run this notebook, you need to use one of the following Databricks runtime(s): **13.3.x-cpu-ml-scala2.12**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc6eb527-3c64-4907-a02f-55521cf4bd39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Other Conventions:\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98b40dd5-6403-4379-a674-6f497c3b09d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username: {DA.username}\")\n",
    "print(f\"Catalog Name: {DA.catalog_name}\")\n",
    "print(f\"Schema Name: {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location: {DA.paths.datasets}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f30c5df8-e97e-4f86-812f-05187d6ab46d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "In this section, we are going to prepare the dataset for our machine learning models. The dataset we'll be working with is the **California housing dataset**.\n",
    "\n",
    "The dataset has been loaded, cleaned and saved to a **feature table**. We will read data directly from this table.\n",
    "\n",
    "Then, we will split the dataset to **train and test** sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "029ba70d-ec1b-4949-af4c-7e25affb5e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Dataset\n",
    "\n",
    "This dataset contains information about housing districts in California and **aims to predict the median house value** for California districts, based on various features.\n",
    "\n",
    "While data cleaning and feature engineering is out of the scope of this demo, we will only map the `ocean_proximity` field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90be245c-29d3-41d1-85b1-8a637e6299d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# read data from the feature store\n",
    "table_name = f\"{DA.catalog_name}.{DA.schema_name}.ca_housing\"\n",
    "feature_data_pd = fe.read_table(name=table_name).toPandas()\n",
    "feature_data_pd = feature_data_pd.drop(columns=['unique_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a82db1ad-fc75-4c00-915d-c3508d2f0dc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ocean_proximity_mapping = {\n",
    "    'NEAR BAY': 1,\n",
    "    '<1H OCEAN': 2,\n",
    "    'INLAND': 3,\n",
    "    'NEAR OCEAN': 4,\n",
    "    'ISLAND': 5\n",
    "}\n",
    "\n",
    "# Replace values in the DataFrame\n",
    "feature_data_pd['ocean_proximity'] = feature_data_pd['ocean_proximity'].replace(ocean_proximity_mapping).astype(float)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "feature_data_pd = feature_data_pd.fillna(0)\n",
    "\n",
    "display(feature_data_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f1b7450-f0f1-4387-9a2f-004943487609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train / Test Split\n",
    "\n",
    "Split the dataset into training and testing sets. This is essential for evaluating the performance of machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a39c740b-9a4b-4f54-8913-d04d1afc9223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"We have {feature_data_pd.shape[0]} records in our source dataset\")\n",
    "\n",
    "# split target variable into its own dataset\n",
    "target_col = \"median_house_value\"\n",
    "X_all = feature_data_pd.drop(labels=target_col, axis=1)\n",
    "y_all = feature_data_pd[target_col]\n",
    "\n",
    "# test / train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.8, random_state=42)\n",
    "print(f\"We have {X_train.shape[0]} records in our training dataset\")\n",
    "print(f\"We have {X_test.shape[0]} records in our test dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f588e500-bdc3-425c-a6ed-cabc6b2ad750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Examine for Potential Co-linearity\n",
    "\n",
    "Now, let's examine the correlations between predictors to identify potential co-linearity. Understanding the relationships between different features can provide insights into the dataset and help us make informed decisions during the modeling process.\n",
    "\n",
    "Let's review the **correlation matrix in tabular format**. Also, we can create a **graph based on the correlation matrix** to easily inspect the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "054eac8e-37cd-41d1-9992-7079b960e38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Combine X and y into a single DataFrame for simplicity\n",
    "data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr = data.corr()\n",
    "\n",
    "# Display correlation matrix\n",
    "pd.set_option('display.max_columns', 10)\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "632a4a4c-8a97-48ea-af10-0385d4414c33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display correlation matrix visually\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(len(corr.columns)):\n",
    "        # Determine the color based on positive or negative correlation\n",
    "        color = 'blue' if corr.iloc[i, j] > 0 else 'red'\n",
    "\n",
    "        # don't fill in circles on the diagonal\n",
    "        fill = not (i == j)\n",
    "\n",
    "        # Plot the circle with size corresponding to the absolute value of correlation\n",
    "        plt.gca().add_patch(plt.Circle((j, i),\n",
    "                                       0.5 * np.abs(corr.iloc[i, j]),\n",
    "                                       color=color,\n",
    "                                       edgecolor=color,\n",
    "                                       fill=fill,\n",
    "                                       alpha=0.5))\n",
    "\n",
    "plt.xlim(-0.5, len(corr.columns) - 0.5)\n",
    "plt.ylim(-0.5, len(corr.columns) - 0.5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xticks(np.arange(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(np.arange(len(corr.columns)), corr.columns)\n",
    "plt.title('Correlogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ae8a3f0-937a-4ce9-9682-a622f2427814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fit a Regression Model\n",
    "\n",
    "To enhance the performance of our regression model, we'll scale our input variables so that they are on a common (standardized) scale. **Standardization ensures that each feature has a mean of 0 and a standard deviation of 1**, which can be beneficial for certain algorithms, including linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b1812b6-8221-495c-9082-f52ba92fd748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "\n",
    "# turn on autologging\n",
    "mlflow.sklearn.autolog(log_input_examples=True)\n",
    "\n",
    "# apply the Standard Scaler to all our input columns\n",
    "std_ct = ColumnTransformer(transformers=[\n",
    "    (\"scaler\", StandardScaler(), [\n",
    "        \"total_bedrooms\", \"total_rooms\", \"housing_median_age\", \n",
    "        \"latitude\", \"longitude\", \"median_income\", \n",
    "        \"population\", \"ocean_proximity\", \"households\"\n",
    "    ])\n",
    "])\n",
    "\n",
    "# pipeline to transform inputs and then pass results to the linear regression model\n",
    "lr_pl = Pipeline(steps=[\n",
    "    (\"tx_inputs\", std_ct),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "# fit our model\n",
    "lr_mdl = lr_pl.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the test set\n",
    "predicted = lr_mdl.predict(X_test)\n",
    "test_r2 = r2_score(y_test, predicted)\n",
    "test_mse = mean_squared_error(y_test, predicted)\n",
    "test_rmse = sqrt(test_mse)\n",
    "test_mape = mean_absolute_percentage_error(y_test, predicted)\n",
    "\n",
    "print(\"Test evaluation summary:\")\n",
    "print(f\"R^2: {test_r2}\")\n",
    "print(f\"MSE: {test_mse}\")\n",
    "print(f\"RMSE: {test_rmse}\")\n",
    "# print(f\"MAPE: {test_mape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c85f89d-7d70-4374-8cbb-09ad08d43991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Examine Model Result\n",
    "\n",
    "Now, let's inspect the results of our linear regression model. We'll examine both the intercept and the coefficients of the fitted model. Additionally, we'll perform a **t-test on each coefficient to assess its significance in contributing to the overall model**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f70dddd6-8a09-4e85-ade0-0bdd8cd0790b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_mdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2da6b686-796a-427d-9c93-d561ffe2058c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Extracting coefficients and intercept\n",
    "coefficients = np.append([lr_mdl.named_steps['lr'].intercept_], lr_mdl.named_steps['lr'].coef_)\n",
    "coefficient_names = ['Intercept'] + X_train.columns.to_list()\n",
    "\n",
    "# Calculating standard errors and other statistics (this is a simplified example)\n",
    "# In a real scenario, you might need to calculate these values more rigorously\n",
    "n_rows, n_cols = X_train.shape\n",
    "X_with_intercept = np.append(np.ones((n_rows, 1)), X_train, axis=1)\n",
    "var_b = test_mse * np.linalg.inv(np.dot(X_with_intercept.T, X_with_intercept)).diagonal()\n",
    "standard_errors = np.sqrt(var_b)\n",
    "t_values = coefficients / standard_errors\n",
    "p_values = [2 * (1 - stats.t.cdf(np.abs(i), (len(X_with_intercept) - 1))) for i in t_values]\n",
    "\n",
    "# Creating a DataFrame for display\n",
    "summary_df = pd.DataFrame({\n",
    "    'Coefficient': coefficients,\n",
    "    'Standard Error': standard_errors,\n",
    "    't-value': t_values,\n",
    "    'p-value': p_values\n",
    "}, index=coefficient_names)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53a85781-ae33-467d-af57-18c1344a54e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "y_pos = np.arange(len(coefficient_names))\n",
    "plt.bar(y_pos, coefficients, align='center', alpha=0.7)\n",
    "plt.xticks(y_pos, coefficient_names, rotation=45)\n",
    "plt.ylabel('Coefficient Size')\n",
    "plt.title('Coefficients in Linear Regression')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d58adb63-d240-4ae8-88e9-c9d440d6b919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52cc3b0b-0408-4d6d-801a-24049f37feed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf8b81b3-593e-49a4-8852-b20084518698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b99030d-5006-481e-928d-ddb007abe90e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "779a662e-f278-462a-bb30-05edd66ffe5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9830dc23-df37-4c78-9b39-e67e23b46ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cda7ebd-c6fd-482a-a93c-75dde7124610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef3dd606-0ce6-4f2a-af06-99156d7f47e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e7364fd-f3dc-4ff7-a00b-14a7ce748d47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aacd09e-bdad-432d-93c0-51da13adc89d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3acdf99-b996-4afc-a863-29748ad0c91f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ce8f0bb-d79a-457e-934a-ac7f402a8464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4 -  1.1a – Training Regression Models 2025-06-17 07_14_19",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
